{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e606c5f-f004-4f6f-b64e-a093ef771c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a183c2a-dd46-4e12-88c5-b47fa61d4eda",
   "metadata": {},
   "source": [
    "### 安装环境后需要重启虚拟机核心"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3fc4293-63f4-465b-836d-61022b503db8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install Pillow==10.1.0 torch==2.1.2 torchvision==0.16.2 transformers==4.40.0 sentencepiece==0.1.99 accelerate==0.30.1 bitsandbytes==0.43.1 peft==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d81b07a-8ff4-4481-b8d7-8e9e98cc53b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-09-16 15:27:44.125737: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-16 15:27:44.243641: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-16 15:27:44.248237: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-09-16 15:27:44.248249: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-09-16 15:27:44.273410: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-16 15:27:46.615513: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-09-16 15:27:46.615569: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-09-16 15:27:46.615576: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages/transformers/quantizers/auto.py:159: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards:   0%|                                                                                                   | 0/2 [00:00<?, ?it/s]/mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.27s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor\n",
    "\n",
    "model_path = '/mnt/ceph/develop/jiawei/ComfyUI/models/LLM/MiniCPMv2_6-prompt-generator'\n",
    "attention = 'sdpa'\n",
    "precision = 'fp16'\n",
    "dtype = {\"bf16\": torch.bfloat16, \"fp16\": torch.float16, \"fp32\": torch.float32}[precision]\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, attn_implementation=attention,\n",
    "                                                         torch_dtype=dtype, load_in_4bit=True, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6453b16-5ebd-438b-b9b8-c8552c98d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "from typing import Union, List\n",
    "from diffusers.image_processor import VaeImageProcessor\n",
    "\n",
    "import PIL.Image\n",
    "from diffusers.utils import export_to_video\n",
    "\n",
    "\n",
    "def pad_frame(img, scale):\n",
    "    _, _, h, w = img.shape\n",
    "    tmp = max(32, int(32 / scale))\n",
    "    ph = ((h - 1) // tmp + 1) * tmp\n",
    "    pw = ((w - 1) // tmp + 1) * tmp\n",
    "    padding = (0,  pw - w, 0, ph - h)\n",
    "    return F.pad(img, padding)\n",
    "\n",
    "def pad_video_of_np(samples, w, h):\n",
    "    print(f\"samples dtype:{samples.dtype}\")\n",
    "    print(f\"samples shape:{samples.shape}\")\n",
    "    output = []\n",
    "    # [f, c, h, w]\n",
    "    for b in range(samples.shape[0]):\n",
    "        frame = samples[b : b + 1]\n",
    "        frame = pad_frame(frame, 1).to(dtype=samples.dtype)\n",
    "        \n",
    "        frame = F.interpolate(frame, size=(h, w))\n",
    "        output.append(frame.squeeze(0)) # (to [f, w, h, c])\n",
    "\n",
    "    image_np = VaeImageProcessor.pt_to_numpy(torch.stack(output))  # (to [49, 512, 480, 3])\n",
    "    image_pil = VaeImageProcessor.numpy_to_pil(image_np)\n",
    "    return image_pil\n",
    "\n",
    "\n",
    "def split_video(video_path, output_dir, start_time, end_time, features_frame, w=720 , h=960 ,chunk_duration=3):\n",
    "    # Open the video file\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    fps = video_capture.get(cv2.CAP_PROP_FPS)  # Get the frames per second\n",
    "    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))  # Total frames in the video\n",
    "    output_files = []\n",
    "    # Calculate start and end frames based on time\n",
    "    start_frame = int(start_time * fps)\n",
    "    end_frame = int(end_time * fps)\n",
    "\n",
    "    video_capture.set(cv2.CAP_PROP_POS_FRAMES, start_frame)  # Set video position to start frame\n",
    "\n",
    "    current_frame = start_frame\n",
    "    chunk_index = 0\n",
    "\n",
    "    while current_frame <= end_frame:\n",
    "        chunk_frames = []\n",
    "        for _ in range(int(chunk_duration * fps)):\n",
    "            ret, frame = video_capture.read()\n",
    "            if not ret:\n",
    "                break  \n",
    "            frame_rgb = frame[..., ::-1]\n",
    "            \n",
    "            # 创建一个新数组，确保 stride 是正的\n",
    "            frame_rgb = frame_rgb.copy()\n",
    "            tensor = torch.from_numpy(frame_rgb).float().to(\"cpu\", non_blocking=True).float() / 255.0\n",
    "            chunk_frames.append(\n",
    "                tensor.permute(2, 0, 1)\n",
    "            )  # to [c, h, w,]\n",
    "            current_frame += 1\n",
    "\n",
    "        if len(chunk_frames) == 0:\n",
    "            break\n",
    "            \n",
    "        # If the last chunk is shorter than expected, repeat the last frame\n",
    "        while len(chunk_frames) < int(chunk_duration * fps):\n",
    "            chunk_frames.append(chunk_frames[-1])\n",
    "            \n",
    "        pt_frame = torch.from_numpy(np.stack(chunk_frames))  # to [f, c, h, w]\n",
    "         \n",
    "        chunk_images = pad_video_of_np(pt_frame,w,h)\n",
    "     \n",
    "        # Save the chunk as a video\n",
    "        output_file = os.path.join(output_dir, f'chunk_{features_frame}_{chunk_index}.mp4')\n",
    "        print(output_file)\n",
    "        save_chunk_as_video(chunk_images, output_file, fps=math.ceil((len(chunk_images) - 1) / 6))\n",
    "        output_files.append(output_file)\n",
    "        chunk_index += 1\n",
    "\n",
    "    video_capture.release()\n",
    "    return output_files\n",
    "    \n",
    " \n",
    "    \n",
    "def save_chunk_as_video(tensor: Union[List[np.ndarray], List[PIL.Image.Image]],video_path, fps: int = 8):\n",
    "    os.makedirs(os.path.dirname(video_path), exist_ok=True)\n",
    "    export_to_video(tensor, video_path, fps=fps)\n",
    "    return video_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57626e8c-6d29-434c-bb60-b1cadb9450ab",
   "metadata": {},
   "source": [
    "#### 使用gpt重新给这个场景增加描述\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ce58a0f-7a25-4b45-b079-46778743cc9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65afd641-6049-4597-a652-9e08dd5c9f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # api_key=\"YOUR_API_KEY\",\n",
    "    base_url=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    import base64\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "def caption_chunk_gpt(video_path, features_caption):\n",
    "\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    ret, first_frame = video_capture.read()\n",
    "    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    video_capture.set(cv2.CAP_PROP_POS_FRAMES, total_frames - 1)\n",
    "    ret, last_frame = video_capture.read()\n",
    "\n",
    "    # Get the frame rate (frames per second)\n",
    "    fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Calculate the duration of the video in seconds\n",
    "    video_duration = total_frames / fps\n",
    "    \n",
    "    video_capture.release()\n",
    "    \n",
    "    first_frame_rgb = first_frame[..., ::-1] \n",
    "    first_frame_rgb = first_frame_rgb.copy()\n",
    "\n",
    "    last_frame_rgb = last_frame[..., ::-1] \n",
    "    last_frame_rgb = last_frame_rgb.copy()\n",
    "    \n",
    "    first_frame_pil_image = Image.fromarray(first_frame_rgb)\n",
    "\n",
    "    last_frame_pil_image = Image.fromarray(last_frame_rgb)\n",
    "\n",
    "    prompt = \"\"\"Follow these steps to create a Midjourney-style long prompt for generating high-quality images: \n",
    "            1. The prompt should include rich details, vivid scenes, and composition information, capturing the important elements that make up the scene. \n",
    "            2. You can appropriately add some details to enhance the vividness and richness of the content, while ensuring that the long prompt does not exceed 256 tokens,you should only return prompt，itself without any additional information\"\"\"\n",
    "\n",
    "    # Prepare the input for the chat method\n",
    "    msgs = [{\"role\": \"user\", \"content\": [first_frame_pil_image, prompt]}]\n",
    "    # Use the chat method\n",
    "    first_frame_generated_text = model.chat(\n",
    "        image=[first_frame_pil_image],\n",
    "        msgs=msgs,\n",
    "        tokenizer=tokenizer,\n",
    "        processor=processor,\n",
    "        max_new_tokens=2048,\n",
    "        sampling=False,\n",
    "        num_beams=3\n",
    "    ) \n",
    "    \n",
    "    # Prepare the input for the chat method\n",
    "    msgs = [{\"role\": \"user\", \"content\": [last_frame_pil_image, prompt]}]\n",
    "    # Use the chat method\n",
    "    last_frame_generated_text = model.chat(\n",
    "        image=[last_frame_pil_image],\n",
    "        msgs=msgs,\n",
    "        tokenizer=tokenizer,\n",
    "        processor=processor,\n",
    "        max_new_tokens=2048,\n",
    "        sampling=False,\n",
    "        num_beams=3\n",
    "    ) \n",
    "    # Sample dictionary of image captions (this should be generated based on your video analysis)\n",
    "    image_captions = {\n",
    "        \"0\": features_caption,\n",
    "        \"1\": first_frame_generated_text,\n",
    "        video_duration: last_frame_generated_text\n",
    "    }\n",
    "    \n",
    "    # Convert image_captions dictionary into a format suitable for new_captions\n",
    "    new_captions = \"\\n\".join([f\"{time}: '{description}'\" for time, description in image_captions.items()])\n",
    "\n",
    "    caption_summary_prompt = f\"\"\"We extracted several frames from this video and described\n",
    "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
    "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
    "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
    "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
    "movements within the video. \\n image_captions={new_captions}\\n\\n\n",
    "You should output your summary directly, and not mention\n",
    "variables like ‘image_captions‘ in your response.\n",
    "Do not include ‘\\\\n’ and the word ’video’ in your response.\n",
    "Do not use introductory phrases such as: \\\"The video presents\\\", \\\"The video depicts\\\", \\\"This video showcases\\\",\n",
    "\\\"The video captures\\\" and so on.\\n Please start the description with the video content directly, such as \\\"A man\n",
    "first sits in a chair, then stands up and walks to the kitchen....\\\"\\n Do not use phrases like: \\\"as the video\n",
    "progressed\\\" and \\\"Throughout the video\\\".\\n Please describe  the content of the video and the changes that occur, in\n",
    "chronological order.\\n Please keep the description of this video within 100 English words.\"\"\"\n",
    "\n",
    "    print(f\"caption_summary_prompt:{caption_summary_prompt}\")\n",
    "    # 减少信息，生成速度可以在0.1秒完成\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"web_search\",\n",
    "            \"web_search\": {\n",
    "                \"enable\": False, \n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-4-flash\",\n",
    "        messages=[ {\"role\": \"user\", \"content\": f\"{caption_summary_prompt}\"}],\n",
    "        temperature=0,\n",
    "        tools=tools,\n",
    "        max_tokens=2000,\n",
    "    ) \n",
    "\n",
    "    caption_summary_text = response.choices[0].message.content\n",
    "    print(f\"caption_summary_text:{caption_summary_text}\")\n",
    "    return first_frame_generated_text, last_frame_generated_text, caption_summary_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae01901b-2ce9-4287-88b2-f0e13398ad87",
   "metadata": {},
   "source": [
    "#### 删除前后时间场景的误差时间 ， 按照3秒每个片段裁剪, fps是原视频的\n",
    "获取第一帧和最后一帧画面，使用gpt整理视频提示词\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da84ff3b-15c6-4216-8fb0-fcdf86442219",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def loadcsv_scene_chunk(scene_csv_path, video_path, videos_output_dir, labels_output_dir):\n",
    "    df = pd.read_csv(scene_csv_path)\n",
    "    \n",
    "    # 计算每个分镜编号的总持续时间\n",
    "    df['持续时间'] = (pd.to_datetime(df['结束时间']) - pd.to_datetime(df['开始时间'])).dt.total_seconds()\n",
    "    grouped_df = df.groupby('分镜')['持续时间'].sum().reset_index()\n",
    "    df = df[df['持续时间'] >= 3]\n",
    "    \n",
    "    df = df.sort_values(by='持续时间', ascending=True)\n",
    "        \n",
    "    # 创建一个新的 DataFrame 来存储行\n",
    "    new_df = pd.DataFrame(columns=df.columns)\n",
    "    # 为新数据添加列\n",
    "    new_df['chunk_index'] = None\n",
    "    new_df['chunk_path'] = None\n",
    "    new_df['first_frame_generated_text'] = None\n",
    "    new_df['last_frame_generated_text'] = None\n",
    "    new_df['caption_summary_text'] = None\n",
    "    # Iterate over each row in the table\n",
    "    for _, row in df.iterrows():\n",
    "        start_time = row['开始时间']\n",
    "        end_time = row['结束时间']\n",
    "        features_caption = row['特征描述']\n",
    "        features_frame = int(row['特征帧'])\n",
    "        # 将行转换为 DataFrame 并追加到 new_df\n",
    "        new_df = pd.concat([new_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "        # 创建一个新的 DataFrame 来存储冗余行\n",
    "        expanded_df = pd.DataFrame(columns=new_df.columns)\n",
    "        # 将开始时间和结束时间解析为时间对象\n",
    "        start_time_obj = datetime.datetime.strptime(start_time, \"%H:%M:%S,%f\")\n",
    "        end_time_obj = datetime.datetime.strptime(end_time, \"%H:%M:%S,%f\")\n",
    "    \n",
    "        # 计算时间区间的秒数\n",
    "        start_seconds = (start_time_obj.hour * 3600 + start_time_obj.minute * 60 + start_time_obj.second +\n",
    "                         start_time_obj.microsecond / 1000000)\n",
    "        end_seconds = (end_time_obj.hour * 3600 + end_time_obj.minute * 60 + end_time_obj.second +\n",
    "                       end_time_obj.microsecond / 1000000)\n",
    "        start_seconds = start_seconds-1\n",
    "        end_seconds = end_seconds-1\n",
    "        # Split the video for each start and end time\n",
    "        output_files = split_video(video_path, videos_output_dir, start_seconds, end_seconds,features_frame)\n",
    "        for index, path in enumerate(output_files):\n",
    "            first_frame_generated_text, last_frame_generated_text, caption_summary_text = caption_chunk_gpt(path, features_caption)\n",
    "            \n",
    "            # Update the corresponding row in new_df with the generated text values\n",
    "            new_df.at[new_df.index[-1], 'chunk_index'] = f'chunk_{features_frame}_{index}'\n",
    "            new_df.at[new_df.index[-1], 'chunk_path'] = path\n",
    "            new_df.at[new_df.index[-1], 'first_frame_generated_text'] = first_frame_generated_text\n",
    "            new_df.at[new_df.index[-1], 'last_frame_generated_text'] = last_frame_generated_text\n",
    "            new_df.at[new_df.index[-1], 'caption_summary_text'] = caption_summary_text\n",
    "            \n",
    "            lable_file = os.path.join(labels_output_dir, f'chunk_{features_frame}_{index}.txt')\n",
    "            # Open the file in write mode\n",
    "            with open(lable_file, 'w') as file: \n",
    "                file.write(caption_summary_text)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d713d948-cf22-47dc-ad74-933066d459b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_output_folder(output_folder):\n",
    "    if not os.path.isdir(output_folder):\n",
    "        print('warning: the folder{} is not exist'.format(output_folder))\n",
    "        # create srt_folder\n",
    "        os.makedirs(output_folder)\n",
    "        print('create folder', output_folder)\n",
    "\n",
    "def split_video_with_chunk(root_path, video_source):\n",
    "    save_path = f'{root_path}/{video_source}/'\n",
    "    video_path=f'{save_path}/{video_source}.mp4' \n",
    " \n",
    "    scene_csv_path=f'{save_path}/scene/{video_source}_scene_keyframe.csv'\n",
    "    videos_output_dir = f'{save_path}/scene_chunks/videos'\n",
    "    labels_output_dir = f'{save_path}/scene_chunks/labels'\n",
    "\n",
    "    scene_chunks_csv_path = f'{save_path}/scene_chunks/{video_source}_scene_chunk_frame.csv'\n",
    "    check_output_folder(videos_output_dir)\n",
    "\n",
    "    check_output_folder(labels_output_dir)\n",
    "    \n",
    "    new_df = loadcsv_scene_chunk(scene_csv_path,video_path,videos_output_dir, labels_output_dir)\n",
    "    \n",
    "    new_df.to_csv(scene_chunks_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec3b902e-42ae-4c57-bc11-2978778e9bd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11884/983159591.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['持续时间'] = (pd.to_datetime(df['结束时间']) - pd.to_datetime(df['开始时间'])).dt.total_seconds()\n",
      "/tmp/ipykernel_11884/983159591.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['持续时间'] = (pd.to_datetime(df['结束时间']) - pd.to_datetime(df['开始时间'])).dt.total_seconds()\n",
      "/tmp/ipykernel_11884/983159591.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, pd.DataFrame([row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_542_0.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_542_1.mp4\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'As the neon lights flicker along the dimly lit corridor, a group of friends strolls hand in hand, their laughter echoing through the space. The walls are adorned with vibrant posters, each telling a story of its own. The atmosphere is one of anticipation and excitement, as if they are about to embark on an adventure. The soft glow of the lights casts a warm hue over the scene, highlighting the joy and camaraderie among the group. The text above them reads, \"晚上，奇奇猪终于来啦！我们一起去吃饭~\" which translates to \"Tonight, Qiqi Pig finally arrives Let's go eat together~\"'\n",
      "1: 'In the dimly lit room, two individuals stand side by side, their backs to the viewer. The person on the left is clad in a vibrant purple coat, their head adorned with a whimsical, fluffy hat that adds a touch of whimsy to their appearance. Their companion, on the right, is dressed in a more subdued outfit, their long hair cascading down their back. The atmosphere is one of quiet anticipation, as if they are about to embark on an exciting adventure. In the background, the faint glow of neon lights and the silhouettes of other people suggest a lively, bustling environment. The scene is filled with a sense of camaraderie and shared excitement, as if they are about to embark on a journey together.'\n",
      "5.916666666666667: 'In the dimly lit ambiance of a cozy restaurant, the air is filled with the soft hum of conversation and the gentle clinking of cutlery. A group of friends, their faces illuminated by the warm glow of candlelight, gather around a table adorned with an array of dishes. The centerpiece is a beautifully presented seafood platter, its vibrant colors contrasting against the dark wooden table. The aroma of freshly baked bread wafts through the air, mingling with the scent of garlic and herbs. In the background, soft jazz music plays, adding to the relaxed and intimate atmosphere. The camera captures this moment from a slightly elevated angle, emphasizing the closeness of the group and the inviting warmth of the setting.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Neon lights flicker in a corridor as friends laugh and stroll, walls adorned with vibrant posters. Two individuals stand in a dimly lit room, one in a purple coat with a fluffy hat, the other with long hair. The scene shifts to a cozy restaurant where friends gather around a candlelit table, enjoying a seafood platter and soft jazz music.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'As the neon lights flicker along the dimly lit corridor, a group of friends strolls hand in hand, their laughter echoing through the space. The walls are adorned with vibrant posters, each telling a story of its own. The atmosphere is one of anticipation and excitement, as if they are about to embark on an adventure. The soft glow of the lights casts a warm hue over the scene, highlighting the joy and camaraderie among the group. The text above them reads, \"晚上，奇奇猪终于来啦！我们一起去吃饭~\" which translates to \"Tonight, Qiqi Pig finally arrives Let's go eat together~\"'\n",
      "1: 'In the dimly lit room, illuminated by the soft glow of a purple light, a sense of anticipation fills the air. A figure, barely visible in the shadows, stands poised as if waiting for the perfect moment to spring into action. The atmosphere is charged with excitement, as if something extraordinary is about to happen. The text, written in a casual, friendly tone, adds a personal touch to the scene, inviting the viewer to join in on the adventure. The composition, with its focus on the mysterious figure and the enigmatic purple light, draws the eye and keeps the viewer engaged, eager to discover what lies ahead.'\n",
      "5.916666666666667: 'In a dimly lit, cozy restaurant, a table is set with a hot pot simmering with a vibrant red broth, surrounded by an array of fresh ingredients ready to be cooked. To the left, neatly arranged slices of thinly cut meat and vegetables await their turn in the pot. In the center, a plate holds a colorful assortment of cherry tomatoes and yellow bell peppers, their bright colors contrasting with the dark table surface. The background is softly blurred, focusing the viewer's attention on the inviting meal setup. The atmosphere suggests a warm, communal dining experience, perfect for sharing and enjoying a variety of flavors.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Neon lights flicker in a corridor, friends laugh and stroll, walls adorned with vibrant posters. A mysterious figure stands in a dimly lit room, anticipation fills the air. In a cozy restaurant, a hot pot simmers with red broth, ingredients and colorful vegetables arranged on a table.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_243_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_243_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'As the train glides smoothly along the tracks, the sunlight streams through the window, casting a warm glow on the interior. The view outside reveals a serene landscape, with gentle hills stretching into the distance and a clear blue sky overhead. The composition of the scene is balanced, with the train's window framing the natural beauty outside, creating a harmonious blend of man-made and natural elements. The atmosphere is peaceful, evoking a sense of calm and tranquility as the train continues its journey.'\n",
      "1: 'As the streetlights flicker on, casting a warm glow on the cobblestone path, a lone figure walks with a sense of purpose. The night air is crisp, and the distant hum of city life can be felt even in the quiet solitude of this moment. The figure's shadow stretches out behind them, merging with the shadows of the old buildings lining the street. In their hand, they carry a lantern, its flame flickering against the darkness, guiding their way. The lantern's light reveals the texture of the cobblestones, the rustling of leaves in the breeze, and the faint scent of night-blooming flowers carried on the wind. This moment, captured in time, is a blend of tranquility and anticipation, as if the figure is on the cusp of embarking on a significant journey.'\n",
      "5.916666666666667: 'As the train glides smoothly along the tracks, the view from the window reveals a serene landscape bathed in the warm glow of the setting sun. The sky is painted with hues of orange and pink, reflecting off the calm waters below. The horizon is dotted with patches of land, their outlines softened by the misty atmosphere. Inside the train, the interior is dimly lit, creating a cozy contrast to the bright exterior. Passengers can be seen enjoying the view, some leaning out of their seats to get a closer look at the picturesque scenery. The overall mood is one of tranquility and relaxation, as if time itself has slowed down for a moment, allowing everyone to appreciate the beauty of the journey.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A train glides smoothly along tracks, sunlight streaming through windows onto a serene landscape of gentle hills and a clear blue sky. A lone figure walks a cobblestone path with a lantern, the night air crisp and city life distant. The train continues, passengers enjoying the setting sun's warm glow and picturesque scenery, the horizon dotted with patches of land.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'As the train glides smoothly along the tracks, the sunlight streams through the window, casting a warm glow on the interior. The view outside reveals a serene landscape, with gentle hills stretching into the distance and a clear blue sky overhead. The composition of the scene is balanced, with the train's window framing the natural beauty outside, creating a harmonious blend of man-made and natural elements. The atmosphere is peaceful, evoking a sense of calm and tranquility as the train continues its journey.'\n",
      "1: 'As the train glides smoothly along the tracks, the view from the window reveals a serene landscape bathed in the warm glow of the setting sun. The sky is painted with hues of orange and pink, casting a soft light on the gently rolling hills in the distance. Below, a river meanders through the valley, its surface shimmering under the fading sunlight. The train's windows reflect the vibrant colors of the sunset, adding a touch of magic to the journey. The atmosphere is calm and peaceful, inviting passengers to sit back and soak in the beauty of the moment.'\n",
      "5.916666666666667: 'In the dimly lit interior of a train compartment, a young woman stands in front of a mirror, her reflection capturing the soft glow of the overhead lights. She is dressed in a cozy white robe, her long hair cascading down her shoulders. A playful cat-eared headband adorns her head, adding a touch of whimsy to her appearance. In her hand, she holds a red phone, using it to take a selfie. The mirror reflects not only her image but also the faint outlines of other passengers seated in the background, their forms blurred and indistinct. The text overlay on the image reads, \"还没化妆，丑丑\" which translates to \"Not yet makeup, ugly,\" adding a layer of self-awareness to the scene. The overall atmosphere is one of quiet introspection, as if the woman is taking a moment to herself amidst the hustle and bustle of travel.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A train glides smoothly along tracks, sunlight streaming through windows onto a serene landscape of gentle hills and a clear blue sky. The setting sun paints the sky in hues of orange and pink, reflecting off the river below. Inside, a young woman in a white robe takes a selfie in a dimly lit compartment, her reflection showing other blurred passengers.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_269_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_269_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'As the train glides smoothly along the tracks, the view outside the window reveals a serene landscape bathed in the warm glow of the sun. The sky is a soft gradient of blue, with wisps of white clouds scattered across it. Below, a river flows gently, its surface shimmering under the sunlight. On either side of the river, lush greenery stretches out, providing a vibrant contrast to the blue of the water and sky. The train itself is sleek and modern, with large windows that offer an unobstructed view of the passing scenery. The atmosphere inside the train is calm and peaceful, with the gentle hum of the engine providing a soothing soundtrack to the journey.'\n",
      "1: 'As the streetlights flicker on, casting a warm glow on the cobblestone path, a lone figure walks with a sense of purpose. The night air is crisp, and the distant hum of city life can be felt even in the quiet solitude of this moment. The figure's shadow stretches out behind them, merging with the shadows of the old buildings lining the street. In their hand, they carry a lantern, its flame flickering against the darkness, guiding their way. The lantern's light reveals the texture of the cobblestones, the rustling of leaves in the breeze, and the faint scent of night-blooming flowers carried on the wind. This moment, captured in time, is a blend of tranquility and anticipation, as if the figure is on the cusp of embarking on a significant journey.'\n",
      "5.916666666666667: 'As the train glides smoothly along the tracks, the view from the window reveals a serene landscape bathed in the warm glow of the setting sun. The sky is painted with hues of orange and pink, reflecting off the calm waters below. The horizon is dotted with patches of land, their outlines softened by the misty atmosphere. Inside the train, the interior is dimly lit, creating a cozy contrast to the bright exterior. Passengers can be seen enjoying the view, some leaning out of their seats to get a closer look at the picturesque scenery. The overall mood is one of tranquility and relaxation, as if time itself has slowed down for a moment, allowing everyone to appreciate the beauty of the journey.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A train glides smoothly along tracks, revealing a serene landscape with a river and lush greenery. A lone figure walks a cobblestone path with a lantern, the night air crisp. The train continues, passengers enjoying the sunset scenery with hues of orange and pink.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'As the train glides smoothly along the tracks, the view outside the window reveals a serene landscape bathed in the warm glow of the sun. The sky is a soft gradient of blue, with wisps of white clouds scattered across it. Below, a river flows gently, its surface shimmering under the sunlight. On either side of the river, lush greenery stretches out, providing a vibrant contrast to the blue of the water and sky. The train itself is sleek and modern, with large windows that offer an unobstructed view of the passing scenery. The atmosphere inside the train is calm and peaceful, with the gentle hum of the engine providing a soothing soundtrack to the journey.'\n",
      "1: 'As the train glides smoothly along the tracks, the view from the window reveals a serene landscape bathed in the warm glow of the setting sun. The sky is painted with hues of orange and pink, casting a soft light on the gently rolling hills in the distance. Below, a river meanders through the valley, its surface shimmering under the fading sunlight. The train's windows reflect the vibrant colors of the sunset, adding a touch of magic to the journey. The atmosphere is calm and peaceful, inviting passengers to sit back and soak in the beauty of the moment.'\n",
      "5.916666666666667: 'In the dimly lit interior of a train compartment, a young woman stands in front of a mirror, her reflection capturing the soft glow of the overhead lights. She is dressed in a cozy white robe, her long hair cascading down her shoulders. A playful cat-eared headband adorns her head, adding a touch of whimsy to her appearance. In her hand, she holds a red phone, using it to take a selfie. The mirror reflects not only her image but also the faint outlines of other passengers seated in the background, their forms blurred and indistinct. The text overlay on the image reads, \"还没化妆，丑丑\" which translates to \"Not yet makeup, ugly,\" adding a layer of self-awareness to the scene. The overall atmosphere is one of quiet introspection, as if the woman is taking a moment to herself amidst the hustle and bustle of travel.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A train glides smoothly along tracks, revealing a serene landscape with a river and lush greenery. The setting sun paints the sky in hues of orange and pink, casting a warm glow on rolling hills. Inside, a young woman in a white robe takes a selfie in a dimly lit compartment, reflecting on her appearance.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_440_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_440_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A bustling airport terminal, filled with travelers in a blur of movement. The ceiling is adorned with geometric patterns, and the overhead lights cast a warm glow on the polished floor. In the foreground, a figure strides purposefully, their face partially obscured by the camera's motion. The background is a tapestry of activity, with signs and advertisements adding splashes of color to the scene. The atmosphere is one of anticipation and excitement, as people prepare for their journeys.'\n",
      "1: 'In a dimly lit room, a young woman sits alone on a plush sofa, her eyes glistening with tears. She holds a crumpled piece of paper, her fingers shaking as she tries to read it. The room is filled with an eerie silence, broken only by the soft sound of her sobs. On the coffee table in front of her lies an open laptop, its screen glowing with the remnants of a video she had been watching. The video had touched her deeply, evoking a flood of emotions that she couldn't control. In the background, a large window reveals a dark, stormy night, the raindrops tapping rhythmically against the glass, adding to the melancholic atmosphere. The woman's heart aches as she contemplates the events of the day, wondering how she ended up alone in this moment of vulnerability.'\n",
      "5.916666666666667: 'A bustling airport terminal, filled with travelers hurrying to their gates. The ceiling is adorned with modern lighting fixtures, casting a warm glow over the busy scene below. People are seen carrying luggage, some pausing to check flight information displayed on large digital boards. The atmosphere is one of anticipation and movement, as passengers prepare for their journeys. In the foreground, a sign in Chinese reads \"到上海啦！\" (Arrived in Shanghai!), adding a personal touch to the universal experience of travel.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A bustling airport terminal filled with travelers in movement, a young woman sitting alone on a sofa with tears, and another busy scene at the same airport with a sign indicating arrival in Shanghai.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A bustling airport terminal, filled with travelers in a blur of movement. The ceiling is adorned with geometric patterns, and the overhead lights cast a warm glow on the polished floor. In the foreground, a figure strides purposefully, their face partially obscured by the camera's motion. The background is a tapestry of activity, with signs and advertisements adding splashes of color to the scene. The atmosphere is one of anticipation and excitement, as people prepare for their journeys.'\n",
      "1: 'A bustling airport terminal, filled with travelers in a blur of movement. The ceiling is adorned with modern lighting fixtures, casting a warm glow on the polished floor below. Digital screens display flight information and advertisements, adding a vibrant splash of color to the scene. Amidst the hustle and bustle, a sense of anticipation hangs in the air as people prepare for their journeys. The atmosphere is one of excitement and the promise of new adventures.'\n",
      "5.916666666666667: 'In the dimly lit corridor, two friends walk side by side, their backs to the camera. The one on the left sports a whimsical bunny hat and a cozy purple hoodie, while the one on the right has long, flowing hair and a plaid skirt. The walls are adorned with vibrant posters, casting a purple hue over the scene. The atmosphere is one of anticipation and excitement, as if they're about to embark on a thrilling adventure. The text on the image reads, \"晚上，奇奇猪终于来啦！我们一起去吃饭~\" which translates to \"Tonight, Qiqi Pig finally arrives Let's go eat together~\"'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A bustling airport terminal filled with travelers in motion, their faces obscured by the camera's movement. The ceiling with geometric patterns and overhead lights casting a warm glow on the polished floor. A figure strides purposefully in the foreground. Digital screens display flight information and advertisements. Two friends walk side by side in a dimly lit corridor, one wearing a bunny hat and purple hoodie, the other with long hair and a plaid skirt. The walls are adorned with vibrant posters.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'A young woman with long, flowing brown hair is seen wearing a cozy white hooded jacket. She is seated outdoors, with a backdrop of lush green trees and a modern building. The lighting suggests it's either early morning or late afternoon, casting a soft glow on her face. She appears relaxed and content, with a gentle smile playing on her lips. The atmosphere is calm and serene, evoking a sense of peacefulness and tranquility.'\n",
      "5.916666666666667: 'In the heart of a bustling market, a young girl with long, flowing brown hair tied into playful pigtails stands out. She dons a cozy white beanie, adding a touch of warmth to her appearance. Her eyes sparkle with excitement as she gazes directly into the camera, a gentle smile playing on her lips. She is dressed in a soft, pastel-colored hoodie that contrasts beautifully with the vibrant colors of the market around her. The background is a blur of activity, with various stalls and people moving about, creating a lively and dynamic atmosphere. The girl's anticipation is palpable as she waits for her turn to perform, her posture relaxed yet full of energy. This moment captures the essence of youth, adventure, and the joy of experiencing new things.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. A young woman with long brown hair sits outdoors in a white hooded jacket, surrounded by lush greenery. A young girl with brown hair and pigtails in a bustling market shows excitement and anticipation for her performance.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'In the heart of a bustling market, a young girl with long, flowing brown hair tied into playful pigtails stands out. She's donned in a cozy white beanie that sits snugly on her head, complementing her warm, inviting smile. Her eyes sparkle with excitement as she gazes directly into the camera, a sense of anticipation evident in her stance. She's dressed in a soft, pastel-colored hoodie that contrasts beautifully with the vibrant colors of the market around her. The background is a blur of activity, with hints of colorful stalls and people going about their day, creating a lively and dynamic atmosphere. The girl's position in the center of the frame draws the viewer's eye, making her the focal point amidst the hustle and bustle of the market.'\n",
      "5.916666666666667: 'In the heart of a bustling market, a young girl with long, flowing brown hair tied into playful pigtails stands out. She is adorned with a delicate white headband, adding a touch of innocence to her appearance. Clad in a cozy white sweater, she exudes a sense of warmth and comfort. Her eyes, full of curiosity and excitement, are fixed on the camera, as if inviting the viewer into her world. The background is a blur of vibrant colors, hinting at the lively atmosphere of the market. The girl's pose, with one hand gently resting on her chin, suggests a moment of contemplation amidst the hustle and bustle. This image captures not just a moment, but a story of youth, wonder, and the simple joys of life.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. A young girl with brown hair and a white beanie stands out in a bustling market, her eyes sparkling with excitement. She's dressed in a pastel-colored hoodie amidst vibrant market colors. The girl, adorned with a white headband and a cozy sweater, contemplates the lively market scene.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'A young girl, adorned in a vibrant red dress embellished with delicate white snowflakes and green holly leaves, stands amidst a snowy landscape. Her hair, styled in playful pigtails, is crowned with a matching red bow, adding a touch of whimsy to her enchanting appearance. She gazes directly into the camera with a gentle smile, her eyes sparkling with a sense of wonder. The background, softly blurred, reveals the serene beauty of a winter wonderland, complete with snow-covered trees and a gentle dusting of snow on the ground. The overall composition exudes a sense of warmth and magic, as if she has stepped straight out of a fairy tale.'\n",
      "5.916666666666667: 'In the heart of a dense, ancient forest, a mystical clearing glows with an ethereal light. At its center stands a towering tree, its bark adorned with vibrant, bioluminescent vines that seem to pulse with a life of their own. The air is thick with the scent of damp earth and blooming flowers, and the sound of a distant, enchanting melody fills the space. A group of fantastical creatures, including a wise old owl, a mischievous pixie, and a gentle unicorn, gather around the tree, their eyes sparkling with curiosity and wonder. Above them, the sky is painted with hues of purple and gold, and a full moon hangs low, casting an otherworldly glow on the scene below. This magical moment, frozen in time, invites the viewer to step into a realm where the impossible becomes possible.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. A young girl in a red dress with snowflakes and holly leaves stands in a snowy landscape, smiling at the camera. In a mystical forest clearing, a tree with bioluminescent vines glows, attracting fantastical creatures like an owl, pixie, and unicorn.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'In the heart of a dense, ancient forest, a majestic waterfall cascades down a rocky cliff, its waters shimmering in the dappled sunlight filtering through the towering trees. The air is thick with the scent of damp earth and blooming wildflowers, and the sound of rushing water blends with the rustling of leaves and chirping of birds. In the foreground, a small clearing reveals a rustic wooden bench, inviting visitors to sit and soak in the tranquil beauty of the surroundings. The sky above is a canvas of soft, pastel hues, reflecting off the water's surface and creating a mesmerizing visual symphony. This idyllic scene is a perfect escape from the hustle and bustle of everyday life, offering a moment of peace and serenity amidst nature's splendor.'\n",
      "5.916666666666667: 'In the heart of a bustling city, amidst the towering skyscrapers and the hum of urban life, two friends, Li and Chen, are preparing to embark on a journey home. The sun is setting, casting a warm glow over the streets, and the air is filled with the scent of street food and the distant laughter of children playing in the park.\n",
      "\n",
      "As they make their way through the crowded metro station, Li and Chen are caught in a moment of hesitation. They glance at each other, unsure if they've taken the right path. The station is alive with the sounds of footsteps and the murmur of conversations, but their minds are focused on the task at hand.\n",
      "\n",
      "Suddenly, they realize they've taken a wrong turn. The signs point in the opposite direction, and they're faced with the daunting task of retracing their steps. Li's heart sinks as they remember the time they've wasted, and Chen tries to keep a positive attitude, offering words of encouragement.\n",
      "\n",
      "With a mix of frustration and determination, they decide to take the next available train, hoping it will lead them closer to their destination. As they board the train, they sit in silence, lost in their thoughts. The city lights outside the window flicker like stars, but inside, they're still searching for their way home.\n",
      "\n",
      "As the train pulls away from the station, Li turns to Chen and says, \"Let's make sure we're on the right track next time.\" Chen nods, a small smile playing on their lips. Together, they face the challenges ahead, their friendship stronger than the obstacles they encounter along the way.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. A majestic waterfall in a dense forest with a rustic bench and tranquil pastel hues follows. In a bustling city, two friends, Li and Chen, navigate a crowded metro station, mistakenly take a wrong turn, and board a train, reflecting on their journey and friendship.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_293_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_293_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'In the dimly lit interior of a train compartment, a young woman stands in front of a mirror, her reflection illuminated by the soft glow of the overhead lights. She is dressed in a cozy white hoodie, and her hair is adorned with a fluffy white hat that adds a touch of whimsy to her appearance. In her hand, she holds a red phone, capturing the moment with a selfie. The mirror reveals a glimpse of the compartment behind her, where other passengers are seated, their forms slightly blurred in the background. The atmosphere is quiet and introspective, as if the woman is taking a moment to herself amidst the journey. The text overlay in the image reads \"还没化妆，丑丑\" which translates to \"Not yet made up, ugly,\" adding a layer of self-awareness to the scene.'\n",
      "1: 'As the train glides smoothly along the tracks, the view from the window reveals a serene landscape bathed in the warm glow of the setting sun. The sky is painted with hues of orange and pink, reflecting off the calm waters of the river that runs parallel to the railway. In the distance, the silhouette of a majestic mountain stands tall, adding a sense of grandeur to the scene. The sunlight filters through the mist, casting a soft, ethereal light over everything, creating a tranquil and picturesque moment that feels like a perfect escape from the hustle and bustle of daily life.'\n",
      "5.916666666666667: 'A young woman, dressed in a cozy white hoodie, stands in a dimly lit bathroom, her reflection captured in the mirror. She holds a red phone case, its vibrant color contrasting with the muted tones of her surroundings. Her hair, tousled and carefree, adds a sense of spontaneity to the scene. The text overlay, \"还没化妆，丑丑\" (which translates to \"Not yet made up, ugly\"), adds a touch of self-deprecating humor, hinting at a moment of self-reflection or preparation. The background is filled with the soft glow of bathroom lights, casting gentle shadows and highlighting the woman's relaxed demeanor. The overall atmosphere is one of casual, everyday life, captured in a single, candid moment.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman in a train compartment takes a selfie, reflecting on her appearance. The train glides through a serene landscape with a setting sun and a majestic mountain. She stands in a bathroom, holding a phone case, reflecting on her day.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'In the dimly lit interior of a train compartment, a young woman stands in front of a mirror, her reflection illuminated by the soft glow of the overhead lights. She is dressed in a cozy white hoodie, and her hair is adorned with a fluffy white hat that adds a touch of whimsy to her appearance. In her hand, she holds a red phone, capturing the moment with a selfie. The mirror reveals a glimpse of the compartment behind her, where other passengers are seated, their forms slightly blurred in the background. The atmosphere is quiet and introspective, as if the woman is taking a moment to herself amidst the journey. The text overlay in the image reads \"还没化妆，丑丑\" which translates to \"Not yet made up, ugly,\" adding a layer of self-awareness to the scene.'\n",
      "1: 'In the dimly lit interior of a cozy café, a young woman stands in front of a large mirror, her reflection capturing the soft glow of the overhead lights. She is dressed in a comfortable gray sweatshirt, its hood pulled up to shield her face from prying eyes. On her head, she wears a whimsical white beanie adorned with playful cat ears, adding a touch of youthful charm to her appearance. In her hand, she holds a vibrant red phone, its screen reflecting her image as she takes a selfie. The café around her buzzes with the murmur of conversation and the clinking of cutlery, creating a warm and inviting atmosphere. The text overlay on the image reads, \"还没化妆，丑丑\" (which translates to \"Not yet makeup, ugly\"), adding a touch of self-deprecating humor to the scene. The composition of the image, with its focus on the woman's reflection and the bustling background, paints a vivid picture of a casual moment captured in time.'\n",
      "5.916666666666667: 'In a dimly lit room, a young woman sits alone on a plush sofa, her eyes glistening with tears. She holds a crumpled piece of paper, her fingers shaking as she tries to read it. The room is filled with an eerie silence, broken only by the soft sound of her sobs. On the coffee table in front of her lies an open laptop, its screen glowing with the remnants of a video she had been watching. The video had touched her deeply, evoking memories she had long buried. As she weeps, she recalls a moment from her past, when she had shared this very room with a close friend. That friend, now absent, had promised to watch the video with her, but had fallen asleep halfway through, leaving her alone to confront her emotions. The room, once filled with laughter and companionship, now echoes with the solitude of her tears.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman stands in a train compartment, taking a selfie with a red phone, reflecting on her appearance. She moves to a café, still selfie-ing, wearing a beanie with cat ears. Later, she sits alone in a dimly lit room, crying and holding a crumpled piece of paper, reflecting on a past memory with a friend.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'A young girl with long, wavy brown hair tied with red ribbons sits in a cozy, dimly lit café. She wears a soft pink blouse with ruffled sleeves and a gentle smile on her face as she gazes directly into the camera. The café has a warm ambiance, with soft lighting casting a gentle glow on the wooden tables and chairs. In the background, a menu board displays various food and drink options, inviting patrons to explore the offerings. The girl's relaxed posture and the inviting atmosphere of the café create a sense of calm and anticipation, as if she is waiting for a friend to join her for a meal.'\n",
      "5.916666666666667: 'A young girl with long, wavy brown hair adorned with red bows sits in a cozy café. She wears a delicate pink blouse with ruffled sleeves, her hand gently resting on her chin as she gazes directly into the camera with a soft, inviting smile. The background is softly blurred, highlighting the warm, inviting ambiance of the café, with soft lighting casting a gentle glow on her face.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. A young girl with brown hair sits in a dimly lit café, smiling and waiting for a friend. The scene transitions to the same girl in the café, her hair adorned with red bows, gazing directly into the camera with a soft smile.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'A young woman with long, wavy brown hair tied with red ribbons sits in a cozy café. She wears a delicate pink blouse with ruffled sleeves and a white collar, her hand gently resting on her chin as she gazes directly into the camera with a soft, inviting smile. The background is softly blurred, highlighting the warm, inviting ambiance of the café, with soft lighting casting a gentle glow on her face.'\n",
      "5.916666666666667: 'A bowl of warm, comforting soup sits on a wooden table, its vibrant yellow exterior contrasting with the rich brown broth. The soup is filled with chunks of soft tofu and fresh green herbs, creating a visually appealing and appetizing dish. A bright yellow spoon rests in the bowl, its handle adorned with a small red label, adding a pop of color to the scene. In the background, a person's hands are visible, gently clasped together, perhaps in anticipation of enjoying the meal. The overall atmosphere is one of warmth and comfort, inviting the viewer to partake in the simple pleasure of a well-prepared bowl of soup.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. One woman with blonde hair and a pink bow, and the other with dark hair and a red ribbon, are dressed in pastel-colored outfits. They are depicted with bright, cheerful expressions, embodying friendship and youthful exuberance. A young woman with long brown hair sits in a café, smiling softly at the camera. A bowl of warm, comforting soup with tofu and herbs sits on a wooden table, surrounded by a warm, inviting atmosphere.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_347_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_347_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'In the stillness of the night, a solitary figure sits on a bench in a dimly lit park, tears streaming down their face. The glow from a nearby streetlamp casts a soft, melancholic light on the scene, highlighting the contours of the figure's face and the gentle ripples in their eyes. The figure's hands are clasped together, fingers interlaced, as if seeking comfort in the cold metal of the bench. In the background, the faint outline of trees sways gently in the breeze, their leaves whispering secrets to the wind. The distant hum of city life fades into insignificance as the figure's sorrow takes center stage, creating an atmosphere of quiet introspection and emotional depth.'\n",
      "1: 'In the dimly lit interior of a cozy train compartment, a young woman stands in front of a mirror, her reflection capturing the soft glow of the overhead lights. She is clad in a plush, white hooded jacket that adds a sense of warmth to the scene. Her hair, peeking out from under the hood, is styled in loose waves, adding a touch of casual elegance. In her hand, she holds a vibrant red phone case, which stands out against the muted tones of her surroundings. The mirror's reflection reveals a glimpse of the train's interior, with other passengers seated in the background, their forms slightly blurred by the focus on the woman in the foreground. The atmosphere is one of quiet anticipation, as if the woman is about to embark on a journey, her unadorned state suggesting a moment of introspection before the hustle and bustle of travel begins.'\n",
      "5.916666666666667: 'In the dimly lit interior of a cozy café, a young woman stands in front of a large mirror, her reflection capturing the soft glow of the overhead lights. She is dressed in a casual gray hoodie, her long hair cascading down her shoulders. On her head, she wears a whimsical white beanie adorned with playful animal ears, adding a touch of charm to her appearance. In her hands, she holds a vibrant red smartphone, its screen reflecting her image as she takes a selfie. The café around her buzzes with activity, with other patrons seated at tables, engaged in conversation and enjoying their meals. The atmosphere is warm and inviting, with the scent of freshly brewed coffee filling the air. The mirror's reflection reveals a glimpse of the café's rustic decor, with wooden furniture and shelves stocked with an array of books and knick-knacks. The woman's expression is one of quiet contemplation, as if she is lost in thought, perhaps reflecting on the day's events or simply enjoying the tranquility of the moment.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A man sits alone on a bench in a park, tears streaming down his face, reflecting on his sorrow. A young woman prepares for a journey, her reflection in a train compartment mirror capturing her anticipation. In a café, another woman takes a selfie, her whimsical beanie and casual attire contrasting with the bustling atmosphere around her.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'In the stillness of the night, a solitary figure sits on a bench in a dimly lit park, tears streaming down their face. The glow from a nearby streetlamp casts a soft, melancholic light on the scene, highlighting the contours of the figure's face and the gentle ripples in their eyes. The figure's hands are clasped together, fingers interlaced, as if seeking comfort in the cold metal of the bench. In the background, the faint outline of trees sways gently in the breeze, their leaves whispering secrets to the wind. The distant hum of city life fades into insignificance as the figure's sorrow takes center stage, creating an atmosphere of quiet introspection and emotional depth.'\n",
      "1: 'In the dimly lit interior of a cozy train compartment, a young woman stands in front of a mirror, her reflection capturing the soft glow of the overhead lights. She is dressed in a comfortable gray robe, her head adorned with a white knitted beanie that adds a touch of warmth to the scene. The beanie's playful pom-pom bobs gently with her movements. In her hand, she holds a vibrant red phone case, its color contrasting with the muted tones of her surroundings. The mirror, framed by the wooden paneling of the compartment, reflects not only her image but also the faint outlines of other passengers seated in the background, their presence adding a sense of life and movement to the scene. The text overlay, \"还没化妆，丑丑\" (which translates to \"Not yet makeup, ugly\"), adds a layer of personal narrative, hinting at the woman's self-awareness and perhaps a touch of self-deprecation. The overall atmosphere is one of quiet introspection, a moment frozen in time as the woman prepares to step out into the world, her true self yet to be revealed.'\n",
      "5.916666666666667: 'A bustling airport terminal, filled with travelers carrying their luggage. The ceiling is adorned with modern lighting fixtures, casting a warm glow on the polished floor below. People are seen walking in various directions, some pausing to check flight information displayed on digital screens overhead. The atmosphere is one of anticipation and movement, as passengers prepare for their journeys.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A man sits alone on a bench in a dimly lit park, tears streaming down his face. A young woman in a train compartment prepares for the day, her reflection in the mirror contrasting with her red phone case. The scene transitions to a bustling airport terminal filled with travelers and anticipation.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'A young woman, dressed in a pristine white nurse's uniform, stands confidently on a bustling city street. Her vibrant blue hair, adorned with delicate pink ribbons, contrasts beautifully with her attire. In her hands, she holds a large, whimsical syringe, its needle gleaming under the sunlight. The background is a blur of activity, with indistinct figures moving about, adding a sense of dynamism to the scene. Her expression is one of gentle determination, as if she's ready to administer a shot of hope and healing to those around her.'\n",
      "5.916666666666667: 'A young girl, adorned in a delicate white dress with intricate lace detailing, stands against a vibrant turquoise backdrop. Her hair, a rich shade of brown, cascades down in soft waves, complemented by a whimsical white hat embellished with a charming bow. Her eyes, full of innocence and wonder, gaze off to the side, as if lost in thought. The overall composition exudes a sense of gentle elegance and youthful charm.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, one dressed in pink and the other in red. A nurse in a white uniform stands confidently on a bustling city street with a whimsical syringe. A young girl in a white dress with a turquoise backdrop stands elegantly, lost in thought.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'A young girl, adorned in a delicate white dress with intricate lace detailing, stands against a vibrant turquoise backdrop. Her hair, a rich shade of brown, cascades down in soft waves, complemented by a whimsical white hat embellished with a charming bow. Her eyes, full of innocence and wonder, gaze off to the side, as if lost in a daydream. The overall composition exudes a sense of youthful elegance and enchantment, capturing a moment of pure, unadulterated joy.'\n",
      "5.916666666666667: 'A young girl, adorned with a delicate white bow in her hair, gazes softly into the distance. She is dressed in a pristine white dress with lace details, evoking a sense of innocence and purity. The background is softly blurred, highlighting her as the focal point, with hints of greenery suggesting an outdoor setting. Her expression is one of quiet contemplation, adding a layer of depth to the scene. The lighting is soft and natural, casting gentle shadows and enhancing the overall ethereal quality of the image.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. A young girl in a white dress with lace details stands against a turquoise backdrop, her hair in waves and eyes full of wonder. Another girl in a white dress with a bow in her hair gazes softly into the distance, surrounded by blurred greenery.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_542_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_542_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'As the neon lights flicker along the dimly lit corridor, a group of friends strolls hand in hand, their laughter echoing through the space. The walls are adorned with vibrant posters, each telling a story of its own. The atmosphere is one of anticipation and excitement, as if they are about to embark on an adventure. The soft glow of the lights casts a warm hue over the scene, highlighting the joy and camaraderie among the group. The text above them reads, \"晚上，奇奇猪终于来啦！我们一起去吃饭~\" which translates to \"Tonight, Qiqi Pig finally arrives Let's go eat together~\"'\n",
      "1: 'A bustling airport terminal, bathed in the soft glow of overhead lights, captures the essence of travel. Passengers, each with their own stories and destinations, move with purpose through the space. The architecture is modern, with sleek lines and expansive glass windows that let in streams of natural light. The ceiling is adorned with geometric patterns, adding a touch of sophistication to the environment. Prominent signs and digital displays guide travelers to their gates, while advertisements add a splash of color to the otherwise neutral tones of the terminal. The atmosphere is one of anticipation and excitement, as people prepare for their journeys.'\n",
      "5.916666666666667: 'As the neon lights flicker along the dimly lit corridor, a couple walks hand in hand, their figures softly illuminated by the ambient glow. The walls are adorned with vibrant posters, adding a splash of color to the otherwise muted tones of the space. The atmosphere is one of quiet anticipation, as if the couple is about to embark on an exciting adventure. The text above them reads, \"晚上，奇奇猪终于来啦！我们一起去吃饭~\" which translates to \"Tonight, Qiqi Pig finally arrives Let's go eat together~\" The scene is filled with a sense of warmth and camaraderie, inviting the viewer to join in on the fun.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A group of friends walks through a neon-lit corridor, laughing and looking at vibrant posters. They reach an airport terminal filled with passengers and modern architecture. Later, a couple walks the same corridor, also laughing and looking at the same posters, preparing for an adventure.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'As the neon lights flicker along the dimly lit corridor, a group of friends strolls hand in hand, their laughter echoing through the space. The walls are adorned with vibrant posters, each telling a story of its own. The atmosphere is one of anticipation and excitement, as if they are about to embark on an adventure. The soft glow of the lights casts a warm hue over the scene, highlighting the joy and camaraderie among the group. The text above them reads, \"晚上，奇奇猪终于来啦！我们一起去吃饭~\" which translates to \"Tonight, Qiqi Pig finally arrives Let's go eat together~\"'\n",
      "1: 'As the neon lights flicker along the dimly lit corridor, a couple walks hand in hand, their laughter echoing through the space. The walls are adorned with vibrant posters, each one telling a story of its own. The atmosphere is one of anticipation and excitement, as if something magical is about to happen. The couple, lost in their own world, seem unaware of the enchantment that surrounds them. This moment, frozen in time, captures the essence of a night filled with adventure and discovery.'\n",
      "5.916666666666667: 'A warm, dimly lit restaurant with a hot pot at the center of the table, surrounded by various dishes and drinks. The hot pot is bubbling with a rich, spicy broth, filled with an assortment of meats and vegetables. To the side, there's a jar of pickled vegetables, a bowl of fresh salad, and a glass jar filled with a dark, possibly sweet beverage. The table is adorned with chopsticks, a plate, and a set of red cups in the background, suggesting a communal dining experience. The atmosphere is cozy and inviting, perfect for a shared meal with friends or family.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A group of friends walks through a neon-lit corridor, laughing and chatting, with vibrant posters on the walls. They enter a cozy restaurant with a hot pot at the center of the table, surrounded by various dishes and drinks, enjoying a communal meal.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'A young woman with long, wavy brown hair and bangs frames her face, her eyes sparkling with excitement. She is dressed in a casual white hoodie, and her lips are painted a soft pink. The background is softly blurred, suggesting an indoor setting with warm, ambient lighting. The text overlay reads, \"cp day2开始了 再次没睡醒的出门了,\" hinting at a shared experience or journey between two individuals. The overall mood is one of anticipation and camaraderie.'\n",
      "5.916666666666667: 'A young woman with long, flowing brown hair is seen wearing a white hooded jacket. The hood is pulled up, partially obscuring her face, adding a sense of mystery. She stands in an urban setting, with blurred buildings and trees in the background, suggesting a bustling city environment. The lighting is soft and diffused, indicating either an overcast day or a shaded area. Her expression is neutral, and she appears to be looking directly at the camera. The overall mood of the image is calm and contemplative.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. A young woman in a white hoodie with pink lips anticipates a shared experience. Another woman in a white hooded jacket stands in an urban setting, looking contemplatively at the camera.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'A young woman with long, flowing brown hair is captured in a candid moment, her face partially obscured by the hood of a light-colored jacket. She stands in an urban setting, with blurred buildings and trees in the background, suggesting a bustling city environment. The overcast sky casts a soft, diffused light over the scene, adding a sense of calmness to the otherwise busy surroundings. Her expression is one of quiet contemplation, as if she's lost in thought amidst the hustle and bustle of city life.'\n",
      "5.916666666666667: 'In the heart of a bustling market, a young girl with long, flowing brown hair tied into playful pigtails stands out. She's adorned in a cozy, pastel-colored sweater that complements her cheerful demeanor. A soft, knitted beanie sits snugly on her head, adding a touch of warmth to her appearance. Her eyes sparkle with excitement as she points directly at the viewer, inviting them into her world. The background is a blur of vibrant colors, hinting at the lively atmosphere of the market, with hints of blue curtains suggesting a stall or booth nearby. The girl's expression is one of eagerness and anticipation, as if she's waiting for someone to join her in her adventure.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. A young woman in a light-colored jacket contemplates in an urban environment. A young girl in a pastel sweater and beanie points excitedly at the viewer in a bustling market.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'A bustling vintage clothing store, filled with an eclectic mix of garments and accessories. The walls are adorned with a variety of colorful dresses, skirts, and blouses, each with its own unique pattern and style. In the foreground, a charming hat with a red and white polka dot ribbon rests on a small table, inviting customers to try it on. The store's shelves are stocked with an assortment of hats, scarves, and jewelry, adding to the nostalgic atmosphere. The lighting is warm and inviting, casting a soft glow on the merchandise and highlighting the textures of the fabrics. The overall ambiance is one of whimsy and charm, reminiscent of a bygone era.'\n",
      "5.916666666666667: 'A whimsical boutique filled with an array of exquisite dresses, each more enchanting than the last. The foreground is dominated by a stunning pink dress, adorned with delicate lace and ruffles, accompanied by a matching hat, evoking a sense of fairy-tale elegance. To the right, a pale green dress with intricate patterns and a flowing skirt suggests a vintage charm. The background is a kaleidoscope of colors, with dresses in shades of white, blue, and red, each meticulously displayed on mannequins. The lighting casts a soft glow over the entire scene, highlighting the textures and details of the fabrics. The atmosphere is one of magical discovery, inviting customers to step into a world of fantasy and fashion.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. They are dressed in pastel-colored outfits, reflecting innocence and playfulness. Next, a bustling vintage clothing store with colorful dresses, skirts, and blouses catches the eye. A charming hat on a table invites customers. The store's warm lighting adds to the nostalgic atmosphere. Finally, a whimsical boutique displays enchanting dresses, lace, and ruffles, creating a magical, fairy-tale-like atmosphere.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'In a quaint boutique adorned with soft, pastel hues, a collection of exquisite dresses graces the mannequins. The centerpiece is a stunning pink gown, its layers of delicate lace and ruffles cascading down like a waterfall of dreams. Beside it, a pale green dress whispers of spring, its corseted bodice and flowing skirt hinting at a bygone era of elegance. The background is a symphony of muted colors, with hints of blue and purple adding depth to the scene. The atmosphere is one of enchantment, as if the dresses are waiting to transport their wearers to a fairytale world.'\n",
      "5.916666666666667: 'In the heart of a whimsical boutique, the walls are adorned with large, vibrant illustrations of playful bunnies, their pink and white hues contrasting against the soft purple backdrop. The bunnies, each holding a heart, seem to invite passersby into a world of fantasy and delight. To the right, a glass display case showcases an array of exquisite dresses, their delicate fabrics and intricate designs hinting at stories of elegance and romance. The floor, made of polished wood, reflects the soft glow of the ambient lighting, adding warmth to the inviting atmosphere. As you step into this enchanting space, you can't help but feel a sense of wonder and joy, as if you've stepped into a fairytale come to life.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. They are dressed in pastel-colored outfits, reflecting innocence and playfulness. In a boutique, a stunning pink gown and a pale green dress are displayed on mannequins, surrounded by vibrant illustrations of bunnies and delicate fabrics. The atmosphere is enchanting, inviting viewers into a fairytale world.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_697_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_697_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'In a dimly lit café, a plate of golden-brown croissants rests on a glossy black table, their flaky layers catching the soft light. Beside it, a round, frosted cake adorned with red and white sprinkles adds a touch of sweetness to the scene. The background is softly blurred, focusing the viewer's attention on the pastries. A glass of iced coffee, its surface reflecting the ambient light, sits nearby, completing the cozy tableau. The atmosphere is one of quiet indulgence, inviting the viewer to partake in the simple pleasures of life.'\n",
      "1: 'In a dimly lit restaurant, a table is set with a hot pot simmering with spicy broth, surrounded by an array of fresh vegetables and meats ready to be cooked. In the foreground, a glass jar filled with a dark, viscous liquid sits next to a bowl of creamy white tofu, garnished with a slice of pink radish. A plate of golden-brown fried food adds a contrasting texture to the scene. The background is softly blurred, focusing attention on the vibrant colors and textures of the food, creating an inviting atmosphere for a communal dining experience.'\n",
      "5.916666666666667: 'In a dimly lit, cozy restaurant, a hot pot simmering with a vibrant red broth takes center stage on a sleek, black countertop. The pot is surrounded by an array of fresh ingredients, including succulent slices of bacon, plump cherry tomatoes, and neatly arranged dumplings. To the right, a white plate holds a colorful assortment of cherry tomatoes, their bright red and yellow hues contrasting beautifully against the plate's pristine whiteness. The background is softly blurred, focusing the viewer's attention on the inviting spread of food. The atmosphere is one of warmth and conviviality, perfect for a shared meal with friends or family.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A plate of golden-brown croissants and a frosted cake sit on a glossy black table in a dimly lit café. A hot pot with spicy broth and fresh ingredients is set in a cozy restaurant. The scene transitions to a similar setting with a vibrant red broth and a colorful assortment of ingredients.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'In a dimly lit café, a plate of golden-brown croissants rests on a glossy black table, their flaky layers catching the soft light. Beside it, a round, frosted cake adorned with red and white sprinkles adds a touch of sweetness to the scene. The background is softly blurred, focusing the viewer's attention on the pastries. A glass of iced coffee, its surface reflecting the ambient light, sits nearby, completing the cozy tableau. The atmosphere is one of quiet indulgence, inviting the viewer to partake in the simple pleasures of life.'\n",
      "1: 'In a dimly lit, cozy restaurant, a hot pot simmering with a rich, spicy broth takes center stage on a sleek, black table. The broth, a vibrant red, is filled with chunks of meat and vegetables, creating a tantalizing aroma. To the right, a plate of cherry tomatoes, their bright red and yellow hues contrasting with the dark table, adds a fresh, colorful touch to the scene. In the background, neatly arranged slices of raw meat await their turn in the hot pot, their pink and white colors hinting at the flavors they will impart to the dish. The overall atmosphere is one of warmth and anticipation, as diners prepare to enjoy a meal that combines the warmth of the broth with the freshness of the vegetables and the richness of the meat.'\n",
      "5.916666666666667: 'A young girl, adorned with a fluffy white hat, gazes softly into the camera, her long brown hair cascading down her shoulders. She is dressed in a cozy, pastel-colored outfit, exuding a sense of warmth and comfort. The background is softly blurred, hinting at a cozy indoor setting with warm, ambient lighting. Her expression is gentle and inviting, as if she's about to share a secret or a heartfelt story.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:In a dimly lit café, a plate of golden-brown croissants rests on a glossy black table, surrounded by a frosted cake and a glass of iced coffee. A cozy restaurant scene follows with a hot pot simmering on a sleek table, filled with chunks of meat and vegetables. A young girl in a fluffy white hat gazes softly into the camera, exuding warmth and comfort.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'A young girl, dressed in a pristine white nurse's uniform, stands out against a soft, blurred background. Her vibrant blue hair, adorned with delicate pink ribbons, adds a touch of whimsy to her appearance. In her hands, she holds a large, whimsical syringe, its needle gleaming under the light. Her expression is one of gentle curiosity, as if she's about to embark on a playful medical adventure. The overall composition of the image suggests a blend of innocence and imagination, capturing the essence of childhood dreams and aspirations.'\n",
      "5.916666666666667: 'A young girl with vibrant blue hair, styled in a bob cut with bangs, stands against a soft-focus background. Her hair is adorned with a delicate purple ribbon tied in a bow. She wears a crisp white shirt with a subtle blue trim, reminiscent of a school uniform. In her hand, she holds a clear plastic bottle with a measurement scale, suggesting a scientific or experimental theme. Her expression is calm and focused, hinting at a sense of purpose or curiosity. The overall atmosphere is one of youthful exploration and discovery.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. A young girl in a nurse's uniform holds a whimsical syringe, exuding curiosity. Another girl with blue hair and a purple ribbon in her hair, wearing a white shirt, holds a plastic bottle with a measurement scale, looking focused and curious.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'A young girl with vibrant blue hair, styled in a bob cut with bangs, stands against a soft-focus background. Her hair is adorned with a delicate purple ribbon tied in a bow. She wears a crisp white shirt with a collar and short sleeves, featuring a subtle blue trim that matches the ribbon in her hair. In her hand, she holds a clear plastic bottle with a measurement scale, suggesting she might be involved in some form of scientific or medical activity. Her expression is calm and focused, hinting at her dedication to her task. The overall atmosphere is one of quiet concentration and youthful determination.'\n",
      "5.916666666666667: 'A young woman, dressed in a pristine white nurse's uniform with blue accents, stands confidently on a bustling street. Her vibrant blue hair, adorned with a delicate pink bow, contrasts beautifully with her attire. In her hands, she holds a large syringe, its needle gleaming under the sunlight. The background is a blur of activity, with indistinct figures moving about, adding a sense of dynamism to the scene. Her expression is serious, hinting at the gravity of her profession. The overall atmosphere is one of anticipation and readiness, as if she is prepared to spring into action at any moment.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. A girl with blue hair and a purple ribbon in her hair focuses on a scientific task. A young woman in a nurse's uniform stands confidently on a bustling street, holding a syringe.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'A young woman, dressed in a pristine white nurse's uniform with blue accents, stands confidently on a bustling street. Her vibrant blue hair, adorned with a delicate pink bow, contrasts beautifully with her attire. In her hands, she holds a large syringe, its needle gleaming under the sunlight. The background is a blur of activity, with people going about their day, adding a sense of depth and dynamism to the scene. The prompt captures the essence of a moment frozen in time, where the ordinary meets the extraordinary.'\n",
      "5.916666666666667: 'A young girl, adorned in a delicate white dress with ruffled sleeves and a matching headband, stands in front of a reflective surface. Her hair is neatly braided, and she gazes directly into the camera with a gentle expression. The background is softly blurred, highlighting her as the focal point. The lighting is soft and natural, casting a gentle glow on her face and dress. The overall mood is serene and dreamy, evoking a sense of innocence and wonder.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, one dressed in pink and the other in red. A nurse in a white uniform stands confidently on a bustling street with a syringe. A young girl in a white dress stands in front of a reflective surface with a serene expression.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'In the heart of a bustling shopping mall, a charming boutique stands out with its whimsical display. The shop's window is adorned with an array of exquisite dresses, each more enchanting than the last. The dresses, crafted with meticulous attention to detail, feature delicate lace, ruffles, and intricate patterns that evoke a sense of fairy-tale elegance. One dress, in particular, catches the eye with its soft pink hue and a charming white teddy bear perched on its shoulder, adding a touch of warmth and playfulness to the ensemble.\n",
      "\n",
      "The boutique's interior is just as captivating, filled with an assortment of accessories and small trinkets that complement the dresses. Each item is thoughtfully arranged, creating a visually pleasing tableau that invites passersby to step inside and explore. The atmosphere is one of fantasy and delight, a haven for those who appreciate the artistry of fashion and the joy of discovery.\n",
      "\n",
      "As you enter the boutique, the air is filled with the sweet scent of cotton candy and the soft glow of fairy lights, enhancing the magical ambiance. The shop's name, written in elegant cursive, hangs above the entrance, beckoning you to enter and lose yourself in the world of whimsy and wonder that lies within.'\n",
      "5.916666666666667: 'In the heart of a whimsical boutique, a collection of exquisite dresses is displayed behind a shimmering glass partition. The dresses, adorned with intricate patterns and sparkling embellishments, reflect the soft glow of the surrounding lights. To the right, a festive Christmas tree stands tall, its branches laden with ornaments and twinkling lights, adding a touch of holiday cheer to the scene. On the left, a large, colorful illustration of a cute bunny character brings a playful element to the space. The walls are painted in a soothing shade of pink, creating a warm and inviting atmosphere. Overlaid on the image is the text \"啊 天堂,\" which translates to \"Oh Heaven\" in English, suggesting a sense of wonder and delight at the beauty of the dresses and the overall ambiance of the boutique.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. They are dressed in pastel-colored outfits, reflecting innocence and playfulness. In a bustling shopping mall, a whimsical boutique with a fairy-tale display catches the eye. The boutique's interior is filled with enchanting dresses, accessories, and trinkets. A festive Christmas tree and a cute bunny illustration add to the magical ambiance.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'In the heart of a whimsical boutique, a collection of exquisite dresses is displayed behind a glass partition. The dresses, each unique in design, shimmer with intricate beadwork and delicate lace, reflecting the soft glow of the pink-hued lighting. To the left, a playful cartoon character adorns the wall, adding a touch of fantasy to the scene. The floor, made of polished wooden planks, leads the eye towards a festive Christmas tree in the background, adorned with twinkling lights and ornaments. The atmosphere is one of enchantment and elegance, inviting passersby to step into a world of fairy-tale fashion.'\n",
      "5.916666666666667: 'In the heart of a bustling shopping mall, a whimsical holiday display captures the essence of festive cheer. Dominating the scene is a vibrant pink Christmas tree, adorned with an array of glittering ornaments and twinkling lights. Nestled at the base of the tree, a charming Santa Claus figurine, dressed in his iconic red suit and hat, stands proudly. The tree is surrounded by an assortment of festive gifts, wrapped in colorful paper and tied with bows, adding to the joyous atmosphere.\n",
      "\n",
      "The display is set against a backdrop of pink walls, creating a warm and inviting ambiance. To the right, a large, playful cutout of a cartoon bunny adds a touch of fun and whimsy to the scene. The floor beneath is a checkerboard pattern of pink and white tiles, complementing the overall color scheme and enhancing the festive feel.\n",
      "\n",
      "In the background, the hustle and bustle of shoppers can be seen, their figures slightly blurred, emphasizing the focus on the holiday display. Despite the busy surroundings, the display stands out as a beacon of holiday spirit, drawing in passersby with its bright colors and cheerful decorations.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. They are dressed in pastel-colored outfits and their expressions are bright and cheerful. In a whimsical boutique, a collection of exquisite dresses with intricate beadwork and lace are displayed. A festive Christmas tree adorned with lights and ornaments stands in the background. In a bustling shopping mall, a vibrant pink Christmas tree with twinkling lights and a Santa Claus figurine stands amidst festive gifts and a cartoon bunny cutout.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'In the heart of a bustling shopping mall, a whimsical holiday display captures the essence of festive cheer. Dominating the scene is a vibrant pink Christmas tree, adorned with glittering ornaments and twinkling lights, standing proudly in the center. To the left, a charming Santa Claus figure, dressed in his iconic red suit with white fur trim and a black belt, adds a touch of traditional holiday spirit. The floor beneath is a checkerboard pattern of pink and white tiles, complementing the overall color scheme. Surrounding the display are shelves filled with an array of festive decorations and gifts, inviting passersby to partake in the holiday joy. The atmosphere is one of warmth and celebration, perfectly encapsulating the magic of the season.'\n",
      "5.916666666666667: 'In the heart of a whimsical boutique, a vibrant red dress adorned with intricate white patterns and playful bunny motifs takes center stage on a mannequin. The dress, complemented by a matching headpiece, exudes a festive charm. To the right, a small pink Christmas tree, decorated with silver ornaments, adds a touch of holiday spirit to the scene. The backdrop is a harmonious blend of soft pink and white hues, creating a cozy and inviting atmosphere. The store's design elements, such as the pink shelving units and the subtle lighting, enhance the overall aesthetic, making it an enchanting space for fashion enthusiasts and holiday shoppers alike.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. A vibrant holiday display with a pink Christmas tree and Santa Claus figure fills a bustling shopping mall. In a boutique, a red dress with bunny motifs and a small Christmas tree adds festive charm.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1268_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1268_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1268_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'In the heart of a bustling city, a young woman with long, flowing brown hair is captured in a moment of tranquility. She stands on a moving walkway, her eyes gently closed as if savoring a peaceful moment amidst the urban hustle. Adorning her head is a cozy, knitted hat with playful animal ears, adding a touch of whimsy to her appearance. She is dressed in a soft, pastel-colored jacket that complements her serene demeanor. The background is a blur of city life, with the metallic sheen of the walkway and the indistinct shapes of passersby creating a sense of depth and movement. The overall composition evokes a sense of calm and introspection, as if the woman is taking a moment to herself in the midst of the city's constant motion.'\n",
      "1: 'In the heart of a bustling city, a young woman with long, flowing brown hair stands on an escalator, her eyes gently closed as if savoring a moment of tranquility amidst the urban chaos. She is adorned with a whimsical white beanie, decorated with playful black cat ears, adding a touch of youthful charm to her appearance. Clad in a cozy pink jacket, she exudes a sense of warmth and comfort. The metallic sheen of the escalator steps reflects the ambient light, creating a dynamic interplay of shadows and highlights. In the background, the blur of city life continues, with indistinct figures and structures suggesting the constant movement and energy of the metropolis. Overlaid on the image is a text in a casual, handwritten font, adding a personal touch to the scene. The overall composition captures a fleeting moment of peace and introspection in the midst of urban hustle and bustle.'\n",
      "5.916666666666667: 'A young woman with long, flowing brown hair, donning a cozy, knitted hat with a playful bear face, stands in front of a moving escalator. She wears a light purple jacket over a black top, her eyes sparkling with a gentle smile as she gazes directly into the camera. The background is softly blurred, emphasizing her as the focal point. The text overlay reads, \"吃饱了 我困了 鸣鸣鸣,\" adding a touch of whimsy to the scene.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with long brown hair stands on a moving walkway, eyes closed, hat adorned with animal ears, in a serene moment amidst a bustling city. She transitions to an escalator, eyes still closed, wearing a whimsical beanie and a cozy jacket. She then stands in front of a moving escalator, hat with a bear face, eyes smiling, in a softly blurred background.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'In the heart of a bustling city, a young woman with long, flowing brown hair is captured in a moment of tranquility. She stands on a moving walkway, her eyes gently closed as if savoring a peaceful moment amidst the urban hustle. Adorning her head is a cozy, knitted hat with playful animal ears, adding a touch of whimsy to her appearance. She is dressed in a soft, pastel-colored jacket that complements her serene demeanor. The background is a blur of city life, with the metallic sheen of the walkway and the indistinct shapes of passersby creating a sense of depth and movement. The overall composition evokes a sense of calm and introspection, as if the woman is taking a moment to herself in the midst of the city's constant motion.'\n",
      "1: 'In the heart of a bustling city, a young woman with long, flowing brown hair and a radiant smile stands atop an escalator. She's donned in a cozy, knitted hat adorned with playful animal ears, adding a touch of whimsy to her appearance. Her eyes sparkle with joy as she gazes directly into the camera, exuding an air of warmth and friendliness. She's dressed in a soft, pastel-colored jacket that complements her cheerful demeanor. The background is a blur of urban life, hinting at the constant movement and energy of the city around her. Overlaid on the image is a text in a casual, handwritten font that reads, \"吃饱了 我困了 呜呜呜,\" adding a personal touch to the scene. The overall composition captures a moment of simple happiness amidst the hustle and bustle of city life.'\n",
      "5.916666666666667: 'In the heart of a dense, ancient forest, a majestic waterfall cascades down a rocky cliff, its waters shimmering in the dappled sunlight filtering through the towering trees. The air is thick with the scent of damp earth and blooming wildflowers, and the sound of rushing water blends with the rustling of leaves and chirping of birds. In the foreground, a small clearing reveals a rustic wooden bench, inviting visitors to sit and soak in the tranquil beauty of the surroundings. The sky above is a canvas of soft, pastel hues, reflecting off the water's surface and creating a mesmerizing visual symphony. This idyllic scene is a perfect escape from the hustle and bustle of everyday life, offering a moment of peace and serenity amidst nature's splendor.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with brown hair and a knitted hat stands on a moving walkway in a bustling city, eyes closed, serene amidst urban chaos. She smiles and gazes at the camera atop an escalator, her pastel jacket complementing her joyful demeanor. In a dense forest, a majestic waterfall cascades down a cliff, surrounded by wildflowers and birds, offering a tranquil escape from the city.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'In the heart of a bustling city, a young woman with long, flowing brown hair is captured in a moment of tranquility. She stands on a moving walkway, her eyes gently closed as if savoring a peaceful moment amidst the urban hustle. Adorning her head is a cozy, knitted hat with playful animal ears, adding a touch of whimsy to her appearance. She is dressed in a soft, pastel-colored jacket that complements her serene demeanor. The background is a blur of city life, with the metallic sheen of the walkway and the indistinct shapes of passersby creating a sense of depth and movement. The overall composition evokes a sense of calm and introspection, as if the woman is taking a moment to herself in the midst of the city's constant motion.'\n",
      "1: 'In the heart of a dense, ancient forest, a majestic waterfall cascades down a rocky cliff, its waters shimmering in the dappled sunlight filtering through the towering trees. The air is thick with the scent of damp earth and blooming wildflowers, and the sound of rushing water blends with the rustling of leaves and chirping of birds. In the foreground, a small clearing reveals a rustic wooden bench, inviting visitors to sit and soak in the serene beauty of the surroundings. The sky above is a canvas of soft, pastel hues, with wispy clouds drifting lazily across the horizon. This tranquil scene is a perfect escape from the hustle and bustle of everyday life, offering a moment of peace and reflection amidst nature's splendor.'\n",
      "5.916666666666667: 'In the heart of a whimsical forest, two young girls stand side by side, their eyes sparkling with excitement. The girl on the left, with her blonde hair cascading down like a waterfall, wears a pink lace headband adorned with a delicate bow. Her companion on the right, with her dark hair neatly tied in a ponytail, sports a brown headband with playful cat ears. Both girls are dressed in charming outfits reminiscent of fairy tale characters, their smiles as bright as the sun. The forest around them is alive with vibrant colors, and the air is filled with the sweet scent of blooming flowers. The girls seem to be on an adventure, their faces lit up with anticipation as they explore the magical world around them.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman in a bustling city finds tranquility on a moving walkway, wearing a whimsical hat and pastel jacket. She is surrounded by the metallic sheen of the walkway and the blur of city life. In a dense forest, a majestic waterfall cascades down a cliff, with a rustic bench inviting visitors to sit and soak in the serene beauty. Two young girls explore a whimsical forest, their excitement evident as they wear fairy tale-inspired outfits and explore the magical surroundings.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1321_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1321_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1321_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair, wearing a cozy white knitted hat with playful animal ears, stands on a moving walkway in a modern subway station. She is dressed in a light purple jacket, her eyes gently closed, and a content smile on her face. The background features sleek, metallic surfaces and the soft glow of ambient lighting, creating a serene atmosphere. The text overlay reads, \"吃饱了 我困了 鸣鸣鸣,\" adding a touch of whimsy to the scene.'\n",
      "1: 'In the heart of a bustling city, a young woman with long, flowing brown hair stands on an escalator, her eyes gently closed as if savoring a moment of tranquility amidst the urban chaos. She is adorned with a whimsical white beanie, decorated with playful black cat ears, adding a touch of youthful charm to her appearance. Clad in a cozy pink jacket, she exudes a sense of warmth and comfort. The metallic sheen of the escalator steps reflects the ambient light, creating a dynamic interplay of shadows and highlights. In the background, the blur of city life continues, with indistinct figures and structures suggesting the constant movement and energy of the metropolis. Overlaid on the image is a text in a casual, handwritten font, adding a personal touch to the scene. The overall composition captures a fleeting moment of peace and introspection in the midst of urban hustle and bustle.'\n",
      "5.916666666666667: 'A young woman with long, flowing brown hair, donning a cozy, knitted hat with a playful bear face, stands in front of a moving escalator. She wears a light purple jacket over a black top, her eyes sparkling with a gentle smile as she gazes directly into the camera. The background is softly blurred, emphasizing her as the focal point. The text overlay reads, \"吃饱了 我困了 鸣鸣鸣,\" adding a touch of whimsy to the scene.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with long brown hair and a white knitted hat with animal ears stands on a moving walkway in a subway station, eyes closed, smiling, surrounded by sleek surfaces and ambient lighting. She then stands on an escalator in a bustling city, eyes closed, wearing a pink jacket, with the cityscape blurred in the background. Lastly, she stands in front of a moving escalator with a bear face hat, eyes sparkling, wearing a purple jacket and black top, with the background softly blurred.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair, wearing a cozy white knitted hat with playful animal ears, stands on a moving walkway in a modern subway station. She is dressed in a light purple jacket, her eyes gently closed, and a content smile on her face. The background features sleek, metallic surfaces and the soft glow of ambient lighting, creating a serene atmosphere. The text overlay reads, \"吃饱了 我困了 鸣鸣鸣,\" adding a touch of whimsy to the scene.'\n",
      "1: 'In the heart of a bustling city, a young woman with long, flowing brown hair and a radiant smile stands atop an escalator. She's donned in a cozy, knitted hat adorned with playful animal ears, adding a touch of whimsy to her appearance. Her eyes sparkle with joy as she gazes directly into the camera, exuding an air of warmth and friendliness. She's dressed in a soft, pastel-colored jacket that complements her cheerful demeanor. The background is a blur of urban life, hinting at the constant movement and energy of the city around her. Overlaid on the image is a text in a casual, handwritten font that reads, \"吃饱了 我困了 呜呜呜,\" adding a personal touch to the scene. The overall composition captures a moment of simple happiness amidst the hustle and bustle of city life.'\n",
      "5.916666666666667: 'In the heart of a dense, ancient forest, a majestic waterfall cascades down a rocky cliff, its waters shimmering in the dappled sunlight filtering through the towering trees. The air is thick with the scent of damp earth and blooming wildflowers, and the sound of rushing water blends with the rustling of leaves and chirping of birds. In the foreground, a small clearing reveals a rustic wooden bench, inviting visitors to sit and soak in the tranquil beauty of the surroundings. The sky above is a canvas of soft, pastel hues, reflecting off the water's surface and creating a mesmerizing visual symphony. This idyllic scene is a perfect escape from the hustle and bustle of everyday life, offering a moment of peace and serenity amidst nature's splendor.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with long brown hair and a white knitted hat stands on a subway walkway, smiling contentedly. She's in a city with a bustling background, then transitions to a serene forest with a majestic waterfall and a rustic bench.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair, wearing a cozy white knitted hat with playful animal ears, stands on a moving walkway in a modern subway station. She is dressed in a light purple jacket, her eyes gently closed, and a content smile on her face. The background features sleek, metallic surfaces and the soft glow of ambient lighting, creating a serene atmosphere. The text overlay reads, \"吃饱了 我困了 鸣鸣鸣,\" adding a touch of whimsy to the scene.'\n",
      "1: 'In the heart of a dense, ancient forest, a majestic waterfall cascades down a rocky cliff, its waters shimmering in the dappled sunlight filtering through the towering trees. The air is thick with the scent of damp earth and blooming wildflowers, and the sound of rushing water blends with the rustling of leaves and chirping of birds. In the foreground, a small clearing reveals a rustic wooden bench, inviting visitors to sit and soak in the serene beauty of the surroundings. The sky above is a canvas of soft, pastel hues, with wispy clouds drifting lazily across the horizon. This tranquil scene is a perfect escape from the hustle and bustle of everyday life, offering a moment of peace and reflection amidst nature's splendor.'\n",
      "5.916666666666667: 'In the heart of a whimsical forest, two young girls stand side by side, their eyes sparkling with excitement. The girl on the left, with her blonde hair cascading down like a waterfall, wears a pink lace headband adorned with a delicate bow. Her companion on the right, with her dark hair neatly tied in a ponytail, sports a brown headband with playful cat ears. Both girls are dressed in charming outfits reminiscent of fairy tale characters, their smiles as bright as the sun. The forest around them is alive with vibrant colors, and the air is filled with the sweet scent of blooming flowers. The girls seem to be on an adventure, their faces lit up with anticipation as they explore the magical world around them.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with long brown hair and a white knitted hat stands on a subway walkway, smiling contentedly. In a dense forest, a majestic waterfall cascades down a cliff, surrounded by wildflowers and rustling leaves. Two girls in fairy tale outfits explore a whimsical forest, their faces alight with excitement.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1125_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1125_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1125_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'In the dimly lit subway station, a young woman stands on the moving walkway, her back to the camera. She's clad in a cozy purple hoodie and black pants, her feet snug in white sneakers. Her head is adorned with a whimsical white bear hat, adding a touch of playfulness to her otherwise casual attire. In her hand, she clutches a black bag, perhaps filled with the day's necessities or treasures from a recent shopping trip. The tiled walls of the station reflect the soft glow of the overhead lights, creating a sense of calm and routine amidst the hustle and bustle of city life.'\n",
      "1: 'A young woman, adorned with a whimsical teddy bear hat, ascends an escalator in a dimly lit subway station. Her white blouse contrasts with the muted tones of the surroundings, and she carries a black bag, suggesting she might be on her way to work or a casual outing. The escalator's metallic steps gleam subtly under the fluorescent lights, and the tiled walls reflect a sense of urban functionality. In the background, another individual, dressed in a dark jacket, walks in the opposite direction, adding a sense of depth and movement to the scene. The overall atmosphere is one of quiet, everyday life in a bustling city.'\n",
      "5.916666666666667: 'A young woman, adorned with a whimsical white bear hat, ascends an escalator in a bustling subway station. She is clad in a cozy white hoodie, her long brown hair flowing behind her. Beside her, a companion in a black hoodie follows, their hands clasped together in anticipation. The walls of the station are lined with beige tiles, and a yellow caution tape marks the edge of the escalator, a stark contrast to the muted tones of the surroundings. The atmosphere is one of quiet anticipation, as the duo makes their way through the underground labyrinth of the city.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman stands on a moving walkway in a dimly lit subway station, wearing a purple hoodie and a bear hat. She ascends an escalator, her white blouse contrasting with the station's muted tones. She's joined by a companion, both of them holding hands. The station's walls are lined with beige tiles and caution tape marks the escalator edge.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'In the dimly lit subway station, a young woman stands on the moving walkway, her back to the camera. She's clad in a cozy purple hoodie and black pants, her feet snug in white sneakers. Her head is adorned with a whimsical white bear hat, adding a touch of playfulness to her otherwise casual attire. In her hand, she clutches a black bag, perhaps filled with the day's necessities or treasures from a recent shopping trip. The tiled walls of the station reflect the soft glow of the overhead lights, creating a sense of calm and routine amidst the hustle and bustle of city life.'\n",
      "1: 'A young woman, adorned with a whimsical white bear hat, ascends an escalator in a bustling subway station. She is clad in a cozy white hoodie, her long brown hair flowing behind her. Beside her, a man in a black jacket and pants walks in the opposite direction, his back to the camera. The escalator's metallic steps gleam under the fluorescent lights, reflecting the hustle and bustle of city life. The walls are lined with advertisements, adding a splash of color to the otherwise monochrome setting. The scene is a snapshot of urban life, capturing the movement and energy of the city as people go about their daily routines.'\n",
      "5.916666666666667: 'A young woman, adorned with a whimsical white bear hat, ascends an escalator in a bustling subway station. Clad in a crisp white coat, she carries a sleek black bag, her gaze directed upwards, perhaps lost in thought or anticipation of her destination. The background is a blur of commuters, each absorbed in their own world, creating a dynamic tapestry of urban life. The lighting is subdued, casting soft shadows and highlighting the textures of the woman's attire and the metallic sheen of the escalator.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman stands on a dimly lit subway station's moving walkway, wearing a purple hoodie and a white bear hat, clutching a black bag. She ascends an escalator, passing a man in a black jacket, her white coat and sleek black bag contrasting with the bustling station. She continues up the escalator, her gaze upward, surrounded by a blur of commuters absorbed in their own worlds.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'In the dimly lit subway station, a young woman stands on the moving walkway, her back to the camera. She's clad in a cozy purple hoodie and black pants, her feet snug in white sneakers. Her head is adorned with a whimsical white bear hat, adding a touch of playfulness to her otherwise casual attire. In her hand, she clutches a black bag, perhaps filled with the day's necessities or treasures from a recent shopping trip. The tiled walls of the station reflect the soft glow of the overhead lights, creating a sense of calm and routine amidst the hustle and bustle of city life.'\n",
      "1: 'A young woman, adorned with a whimsical white bear hat, ascends an escalator in a bustling subway station. She is clad in a crisp white coat, her black hair peeking out from beneath the hat's fluffy brim. In her hand, she carries a sleek black bag, her steps steady and purposeful. The station around her is a hive of activity, with other commuters ascending and descending the escalator, their faces a blur of motion. The walls of the station are a muted gray, providing a stark contrast to the vibrant energy of the people within. The scene is a snapshot of urban life, a moment frozen in time amidst the constant ebb and flow of city dwellers.'\n",
      "5.916666666666667: 'A young woman with long, flowing brown hair is seated on an escalator, her eyes gently closed as if she's taking a moment to rest. She's wearing a cozy, fluffy white beanie adorned with a cute animal face, adding a touch of whimsy to her appearance. She's dressed in a soft, pastel-colored jacket that complements her relaxed demeanor. The metallic sheen of the escalator steps reflects the ambient light, creating a sense of depth and movement in the scene. The background is softly blurred, drawing focus to her peaceful expression and the comforting textures of her surroundings.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman stands on a dimly lit subway station's moving walkway, wearing a purple hoodie and white bear hat, clutching a black bag. She ascends an escalator, her steps purposeful, amidst bustling activity. Later, she sits on an escalator, eyes gently closed, wearing a fluffy white beanie and pastel jacket, reflecting a moment of tranquility in the urban chaos.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1139_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1139_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1139_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman, donning a whimsical white bunny hat, ascends an escalator in a bustling subway station. Her white blouse contrasts with her dark pants, and she carries a black bag, suggesting she's on her way to work or school. The background is a blur of other commuters, each absorbed in their own world, creating a sense of motion and urban life. The lighting is artificial, typical of an underground setting, casting soft shadows and highlighting the textures of the woman's clothing and the metallic surface of the escalator.'\n",
      "1: 'A young woman, adorned with a whimsical teddy bear hat, ascends an escalator in a dimly lit subway station. Her white blouse contrasts with the muted tones of the surroundings, and she carries a black bag, suggesting she might be on her way to work or a casual outing. The escalator's metallic steps gleam subtly under the fluorescent lights, and the tiled walls reflect a sense of urban functionality. In the background, another individual, dressed in a dark jacket, walks in the opposite direction, adding a sense of depth and movement to the scene. The overall atmosphere is one of quiet, everyday life in a bustling city.'\n",
      "5.916666666666667: 'A young woman, adorned with a whimsical white bear hat, ascends an escalator in a bustling subway station. She is clad in a cozy white hoodie, her long brown hair flowing behind her. Beside her, a companion in a black hoodie follows, their hands clasped together in anticipation. The walls of the station are lined with beige tiles, and a yellow caution tape marks the edge of the escalator, a stark contrast to the muted tones of the surroundings. The atmosphere is one of quiet anticipation, as the duo makes their way through the underground labyrinth of the city.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman in a white bunny hat ascends an escalator in a busy subway station, her white blouse contrasting with dark pants and a black bag. She's surrounded by other commuters absorbed in their own worlds. She switches to a teddy bear hat and continues up the escalator, the station's dim lighting highlighting her clothing and the metallic steps. Later, she's with a companion, both wearing hoodies, as they ascend the escalator together, anticipation in the air.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman, donning a whimsical white bunny hat, ascends an escalator in a bustling subway station. Her white blouse contrasts with her dark pants, and she carries a black bag, suggesting she's on her way to work or school. The background is a blur of other commuters, each absorbed in their own world, creating a sense of motion and urban life. The lighting is artificial, typical of an underground setting, casting soft shadows and highlighting the textures of the woman's clothing and the metallic surface of the escalator.'\n",
      "1: 'A young woman, adorned with a whimsical white bear hat, ascends an escalator in a bustling subway station. She is clad in a cozy white hoodie, her long brown hair flowing behind her. Beside her, a man in a black jacket and pants walks in the opposite direction, his back to the camera. The escalator's metallic steps gleam under the fluorescent lights, reflecting the hustle and bustle of city life. The walls are lined with advertisements, adding a splash of color to the otherwise monochrome setting. The scene is a snapshot of urban life, capturing the movement and energy of the city as people go about their daily routines.'\n",
      "5.916666666666667: 'A young woman, adorned with a whimsical white bear hat, ascends an escalator in a bustling subway station. Clad in a crisp white coat, she carries a sleek black bag, her gaze directed upwards, perhaps lost in thought or anticipation of her destination. The background is a blur of commuters, each absorbed in their own world, creating a dynamic tapestry of urban life. The lighting is subdued, casting soft shadows and highlighting the textures of the woman's attire and the metallic sheen of the escalator.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman in a white bunny hat ascends an escalator in a busy subway station, her white blouse contrasting with dark pants and a black bag. She's surrounded by a blur of other commuters, each lost in their own world. She switches to a white bear hat and a cozy hoodie, with a man in a black jacket walking in the opposite direction. She later dons a white coat and a sleek black bag, her gaze directed upwards, lost in thought. The background is filled with advertisements and the metallic steps of the escalator gleam under fluorescent lights.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman, donning a whimsical white bunny hat, ascends an escalator in a bustling subway station. Her white blouse contrasts with her dark pants, and she carries a black bag, suggesting she's on her way to work or school. The background is a blur of other commuters, each absorbed in their own world, creating a sense of motion and urban life. The lighting is artificial, typical of an underground setting, casting soft shadows and highlighting the textures of the woman's clothing and the metallic surface of the escalator.'\n",
      "1: 'A young woman, adorned with a whimsical white bear hat, ascends an escalator in a bustling subway station. She is clad in a crisp white coat, her black hair peeking out from beneath the hat's fluffy brim. In her hand, she carries a sleek black bag, her steps steady and purposeful. The station around her is a hive of activity, with other commuters ascending and descending the escalator, their faces a blur of motion. The walls of the station are a muted gray, providing a stark contrast to the vibrant energy of the people within. The scene is a snapshot of urban life, a moment frozen in time amidst the constant ebb and flow of city dwellers.'\n",
      "5.916666666666667: 'A young woman with long, flowing brown hair is seated on an escalator, her eyes gently closed as if she's taking a moment to rest. She's wearing a cozy, fluffy white beanie adorned with a cute animal face, adding a touch of whimsy to her appearance. She's dressed in a soft, pastel-colored jacket that complements her relaxed demeanor. The metallic sheen of the escalator steps reflects the ambient light, creating a sense of depth and movement in the scene. The background is softly blurred, drawing focus to her peaceful expression and the comforting textures of her surroundings.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman in a white bunny hat ascends an escalator in a busy subway station, her white blouse contrasting with dark pants and black bag. She's surrounded by a blur of other commuters, each lost in their own world. She later dons a white bear hat and a white coat, her black hair visible beneath the hat's brim, as she continues her journey. A moment later, a woman with long brown hair sits on the escalator, eyes gently closed, wearing a fluffy white beanie and a pastel jacket, reflecting a moment of tranquility amidst the urban chaos.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1029_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1029_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1029_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman, donning a whimsical white bear hat, ascends an escalator in a bustling subway station. Her white blouse contrasts with the black attire of the person ahead of her. The metallic sheen of the escalator steps gleams under the fluorescent lights, reflecting the hurried footsteps of commuters. The walls are adorned with a pattern of tiles, adding a touch of urban charm to the scene. As she moves upward, she seems lost in thought, perhaps contemplating her destination or reminiscing about past adventures. The ambient noise of the station mingles with the hum of the escalator, creating a symphony of city life.'\n",
      "1: 'A young woman, adorned with a whimsical teddy bear hat, ascends an escalator in a dimly lit subway station. Her white blouse contrasts with the muted tones of the surroundings, and she carries a black bag, suggesting she might be on her way to work or a casual outing. The escalator's metallic steps gleam subtly under the fluorescent lights, and the tiled walls reflect a sense of urban functionality. In the background, another individual, dressed in a dark jacket, walks in the opposite direction, adding a sense of depth and movement to the scene. The overall atmosphere is one of quiet, everyday life in a bustling city.'\n",
      "5.916666666666667: 'A young woman, adorned with a whimsical white bear hat, ascends an escalator in a bustling subway station. She is clad in a cozy white hoodie, her long brown hair flowing behind her. Beside her, a companion in a black hoodie follows, their hands clasped together in anticipation. The walls of the station are lined with beige tiles, and a yellow caution tape marks the edge of the escalator, a stark contrast to the muted tones of the surroundings. The atmosphere is one of quiet anticipation, as the duo makes their way through the underground labyrinth of the city.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman in a whimsical white bear hat ascends an escalator in a subway station, her white blouse contrasting with the black attire of others. She seems lost in thought, surrounded by the bustling city life. She's joined by a companion, and they ascend the escalator together, their hands clasped.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman, donning a whimsical white bear hat, ascends an escalator in a bustling subway station. Her white blouse contrasts with the black attire of the person ahead of her. The metallic sheen of the escalator steps gleams under the fluorescent lights, reflecting the hurried footsteps of commuters. The walls are adorned with a pattern of tiles, adding a touch of urban charm to the scene. As she moves upward, she seems lost in thought, perhaps contemplating her destination or reminiscing about past adventures. The ambient noise of the station mingles with the hum of the escalator, creating a symphony of city life.'\n",
      "1: 'A young woman, adorned with a whimsical white bear hat, ascends an escalator in a bustling subway station. She is clad in a cozy white hoodie, her long brown hair flowing behind her. Beside her, a man in a black jacket and pants walks in the opposite direction, his back to the camera. The escalator's metallic steps gleam under the fluorescent lights, reflecting the hustle and bustle of city life. The walls are lined with advertisements, adding a splash of color to the otherwise monochrome setting. The scene is a snapshot of urban life, capturing the movement and energy of the city as people go about their daily routines.'\n",
      "5.916666666666667: 'A young woman, adorned with a whimsical white bear hat, ascends an escalator in a bustling subway station. Clad in a crisp white coat, she carries a sleek black bag, her gaze directed upwards, perhaps lost in thought or anticipation of her destination. The background is a blur of commuters, each absorbed in their own world, creating a dynamic tapestry of urban life. The lighting is subdued, casting soft shadows and highlighting the textures of the woman's attire and the metallic sheen of the escalator.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman in a whimsical white bear hat ascends an escalator in a busy subway station. She wears a white blouse and a cozy white hoodie, her hair flowing behind her. A man in a black jacket walks in the opposite direction. The escalator's steps gleam under fluorescent lights, reflecting the bustling station. Advertisements line the walls. She wears a white coat and carries a black bag, her gaze directed upwards, lost in thought. The background is a blur of commuters absorbed in their own worlds.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman, donning a whimsical white bear hat, ascends an escalator in a bustling subway station. Her white blouse contrasts with the black attire of the person ahead of her. The metallic sheen of the escalator steps gleams under the fluorescent lights, reflecting the hurried footsteps of commuters. The walls are adorned with a pattern of tiles, adding a touch of urban charm to the scene. As she moves upward, she seems lost in thought, perhaps contemplating her destination or reminiscing about past adventures. The ambient noise of the station mingles with the hum of the escalator, creating a symphony of city life.'\n",
      "1: 'A young woman, adorned with a whimsical white bear hat, ascends an escalator in a bustling subway station. She is clad in a crisp white coat, her black hair peeking out from beneath the hat's fluffy brim. In her hand, she carries a sleek black bag, her steps steady and purposeful. The station around her is a hive of activity, with other commuters ascending and descending the escalator, their faces a blur of motion. The walls of the station are a muted gray, providing a stark contrast to the vibrant energy of the people within. The scene is a snapshot of urban life, a moment frozen in time amidst the constant ebb and flow of city dwellers.'\n",
      "5.916666666666667: 'A young woman with long, flowing brown hair is seated on an escalator, her eyes gently closed as if she's taking a moment to rest. She's wearing a cozy, fluffy white beanie adorned with a cute animal face, adding a touch of whimsy to her appearance. She's dressed in a soft, pastel-colored jacket that complements her relaxed demeanor. The metallic sheen of the escalator steps reflects the ambient light, creating a sense of depth and movement in the scene. The background is softly blurred, drawing focus to her peaceful expression and the comforting textures of her surroundings.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman in a whimsical white bear hat ascends an escalator in a busy subway station. She wears a white blouse and a black coat, carrying a black bag. The station is lively with other commuters, and the walls are adorned with tiles. She pauses on the escalator, eyes closed, wearing a fluffy white beanie, before continuing her journey.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1029_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1029_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1029_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1029_3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman, donning a whimsical white bear hat, ascends an escalator in a bustling subway station. Her white blouse contrasts with the black attire of the person ahead of her. The metallic sheen of the escalator steps gleams under the fluorescent lights, reflecting the hurried footsteps of commuters. The walls are adorned with a pattern of tiles, adding a touch of urban charm to the scene. As she moves upward, she seems lost in thought, perhaps contemplating her destination or reminiscing about past adventures. The ambient noise of the station mingles with the hum of the escalator, creating a symphony of city life.'\n",
      "1: 'In the heart of a bustling city, a young woman with long, flowing brown hair stands confidently in front of a vibrant storefront. She dons a whimsical white beanie adorned with a playful black and white bear face, adding a touch of charm to her appearance. With a mischievous glint in her eye, she winks playfully at the camera, her hand raised to form a peace sign. The background is a lively tableau of urban life, with colorful posters and signs adding to the dynamic atmosphere. The text overlay, written in a casual, friendly font, reads: \"妆画得很淡 可能和后面的我长得不太一样 不要在意\" which translates to \"The makeup is very light, maybe the one behind me looks quite different, don't worry about it.\" This prompt captures a moment of youthful exuberance and self-assuredness amidst the hustle and bustle of city life.'\n",
      "5.916666666666667: 'In the heart of a bustling city, a young woman with long, flowing brown hair stands out against the urban backdrop. She dons a whimsical white beanie adorned with playful black cat ears, adding a touch of charm to her appearance. Clad in a soft pink jacket, she exudes a sense of warmth and friendliness. The background is a blur of city life, with indistinct figures and structures suggesting the constant movement and energy of the urban environment. Overlaid on the image is text in a casual, handwritten font, offering a personal message that adds a layer of intimacy to the scene. The overall composition captures a moment of quiet amidst the city's hustle and bustle, inviting viewers to pause and appreciate the beauty in everyday life.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman in a white bear hat ascends an escalator in a subway station, her blouse contrasting with the person ahead. She stands confidently in front of a vibrant storefront, winking playfully at the camera. She's dressed in a white beanie with black cat ears and a pink jacket, exuding warmth. The background is a blur of city life, with indistinct figures and structures.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman, donning a whimsical white bear hat, ascends an escalator in a bustling subway station. Her white blouse contrasts with the black attire of the person ahead of her. The metallic sheen of the escalator steps gleams under the fluorescent lights, reflecting the hurried footsteps of commuters. The walls are adorned with a pattern of tiles, adding a touch of urban charm to the scene. As she moves upward, she seems lost in thought, perhaps contemplating her destination or reminiscing about past adventures. The ambient noise of the station mingles with the hum of the escalator, creating a symphony of city life.'\n",
      "1: 'In the heart of a bustling city, a young woman with long, flowing brown hair stands out against the urban backdrop. She is adorned with a whimsical, knitted hat shaped like a bear's head, adding a touch of playfulness to her appearance. Clad in a soft, pastel-colored jacket, she exudes a sense of warmth and comfort. The background is a blur of city life, with streaks of light and color suggesting the movement of people and vehicles. Overlaid on the image is text in a casual, handwritten font, offering a personal touch and inviting the viewer to connect with the subject on a deeper level. The overall composition captures a moment of quiet amidst the hustle and bustle, inviting the viewer to pause and appreciate the beauty in everyday life.'\n",
      "5.916666666666667: 'A young woman with long, dark hair and a playful expression is the focal point of this image. She is wearing a cozy, knitted hat adorned with a cute animal face, adding a touch of whimsy to her appearance. Her makeup is minimal, giving her a natural and fresh look. She is dressed in a casual, light-colored hoodie, which contrasts with the darker tones of her hair. The background is slightly blurred, but it appears to be a bustling urban setting, possibly a shopping mall or a busy street, with other people and storefronts visible in the distance. The lighting is soft and diffused, suggesting an overcast day or a shaded area. The overall mood of the image is cheerful and relaxed, capturing a candid moment in the woman's day.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman in a whimsical bear hat ascends an escalator in a subway station, her white blouse contrasting with the black attire of those around her. She stands out in a bustling cityscape, her pastel jacket and bear hat adding warmth and playfulness. She's captured in a shopping mall or busy street, her casual hoodie contrasting with her dark hair and minimal makeup.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman, donning a whimsical white bear hat, ascends an escalator in a bustling subway station. Her white blouse contrasts with the black attire of the person ahead of her. The metallic sheen of the escalator steps gleams under the fluorescent lights, reflecting the hurried footsteps of commuters. The walls are adorned with a pattern of tiles, adding a touch of urban charm to the scene. As she moves upward, she seems lost in thought, perhaps contemplating her destination or reminiscing about past adventures. The ambient noise of the station mingles with the hum of the escalator, creating a symphony of city life.'\n",
      "1: 'A young woman, adorned with a whimsical panda hat, sits in a bustling café. Her long, dark hair cascades down her shoulders, contrasting with her light-colored hoodie. The background is a blur of activity, with patrons engaged in conversation and the soft hum of the café's ambiance. She holds up a peace sign with her right hand, a playful gesture that adds a touch of charm to the scene. The text overlay reads, \"妆画得很淡 可能和后面的我长得不太一样 不要在意,\" adding a personal touch to the image.'\n",
      "5.916666666666667: 'A young woman, clad in a cozy white hoodie and a whimsical bear hat, ascends an escalator in a bustling subway station. Her hair, peeking out from under the hat, sways gently with each step. She carries a black bag, perhaps filled with the day's necessities or treasures from a recent shopping trip. The station is alive with the hum of activity, the metallic gleam of the escalator contrasting with the muted tones of the tiled walls. In the background, another commuter, dressed in a sleek black jacket, walks in the opposite direction, adding to the dynamic tapestry of city life. The scene is a snapshot of urban existence, capturing the blend of individual stories within the collective rhythm of the city.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman in a white bear hat ascends an escalator in a subway station, her blouse contrasting with the person ahead. She sits in a café with a panda hat, holding up a peace sign. Later, she's seen again ascending the same escalator, her hair peeking out from under the hat, carrying a black bag.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman, donning a whimsical white bear hat, ascends an escalator in a bustling subway station. Her white blouse contrasts with the black attire of the person ahead of her. The metallic sheen of the escalator steps gleams under the fluorescent lights, reflecting the hurried footsteps of commuters. The walls are adorned with a pattern of tiles, adding a touch of urban charm to the scene. As she moves upward, she seems lost in thought, perhaps contemplating her destination or reminiscing about past adventures. The ambient noise of the station mingles with the hum of the escalator, creating a symphony of city life.'\n",
      "1: 'A young woman, adorned with a plush bear hat, ascends an escalator in a dimly lit subway station. She is dressed in a casual white hoodie and carries a black bag, her gaze directed downwards as she navigates the metallic steps. Behind her, a man in a black jacket follows, his figure slightly blurred in the low light. The walls of the station are lined with beige tiles, and a yellow caution tape marks the edge of the escalator, adding a stark contrast to the otherwise muted tones of the scene. The atmosphere is quiet, the only sounds being the soft hum of the escalator and the distant murmur of commuters.'\n",
      "5.916666666666667: 'A young woman, clad in a cozy purple hoodie and a whimsical white unicorn hat, ascends the stairs in a bustling subway station. Her hair, peeking out from under the hat, sways gently with each step. The tiled walls of the station reflect the ambient light, creating a mosaic of grays and whites. In her hand, she carries a black bag, perhaps filled with the day's necessities or treasures from a recent shopping trip. The scene is a blend of urban life and personal whimsy, capturing a moment of quiet determination amidst the hustle and bustle of the city.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman in a whimsical white bear hat ascends an escalator in a subway station, her white blouse contrasting with the black attire of the person ahead. The escalator's metallic steps gleam under fluorescent lights, reflecting the hurried footsteps of commuters. She seems lost in thought, contemplating her destination or past adventures. In the next frame, she's in a dimly lit station, her gaze downward as she navigates the escalator steps. A man in a black jacket follows, blurred in the low light. The walls are beige with yellow caution tape, adding contrast. Finally, she's in a bustling station, wearing a purple hoodie and a white unicorn hat, her hair swaying with each step. She carries a black bag, reflecting a blend of urban life and personal whimsy.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_774_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_774_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_774_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_774_3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair and a playful expression is the focal point of this image. She is wearing a cozy, white beanie adorned with a cute animal face, adding a touch of whimsy to her appearance. The setting appears to be a bustling indoor area, possibly a shopping mall or a food court, with various storefronts and people in the background. The lighting is bright and inviting, highlighting the woman's features and the textures of her beanie. The overall mood of the image is cheerful and relaxed, capturing a candid moment in the woman's day.'\n",
      "1: 'In the dimly lit corridor, adorned with vibrant posters on the walls, two figures walk side by side. One, clad in a purple jacket, carries a bag, while the other, in a white top, holds a phone. The atmosphere is one of quiet anticipation, as if they are about to embark on an exciting adventure. The text above them reads, \"晚上，奇奇猪终于来啦！我们一起去吃饭~\" which translates to \"Tonight, Qiqi Pig finally arrives Let's go eat together~\" The scene is filled with a sense of camaraderie and shared excitement.'\n",
      "5.916666666666667: 'A long prompt for generating a high-quality image based on the provided photograph might look like this:\n",
      "\n",
      "\"Create a vibrant and appetizing image of a bustling buffet line in a modern restaurant. The main focus should be on a stainless steel serving tray filled with two distinct hot pot dishes, one with a rich, dark broth and the other with a bright, spicy red broth. The dark broth contains visible chunks of meat and vegetables, while the red broth is filled with what appears to be tofu and other ingredients. To the left of the tray, there's a stack of neatly arranged pink cups, possibly for dipping sauces. In the foreground, there's a plate with a piece of fried food, possibly chicken, garnished with green herbs. The background is softly blurred, emphasizing the food in the foreground. The lighting is warm and inviting, highlighting the textures and colors of the dishes. The overall composition should convey a sense of freshness, variety, and culinary delight.\"\n",
      "\n",
      "Please note that the token limit of 256 tokens is strictly adhered to, and no additional information is provided beyond the prompt itself.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with a playful expression and a cute beanie is in a busy indoor area, possibly a mall. Two friends excitedly walk down a corridor with a poster about a dinner. A detailed description of a high-quality image of a buffet line in a modern restaurant is provided.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair and a playful expression is the focal point of this image. She is wearing a cozy, white beanie adorned with a cute animal face, adding a touch of whimsy to her appearance. The setting appears to be a bustling indoor area, possibly a shopping mall or a food court, with various storefronts and people in the background. The lighting is bright and inviting, highlighting the woman's features and the textures of her beanie. The overall mood of the image is cheerful and relaxed, capturing a candid moment in the woman's day.'\n",
      "1: 'A long prompt for generating a high-quality image based on the provided photograph might look like this:\n",
      "\n",
      "\"In a bustling, dimly-lit restaurant, a vibrant hot pot buffet beckons diners with its array of richly colored broths. Two distinct pots sit side by side, one brimming with a fiery red broth and the other with a deep, savory brown broth, both filled with an assortment of ingredients like mushrooms, vegetables, and meats. To the left, a stack of neatly arranged pink cups waits to be filled, adding a pop of color to the scene. The stainless steel counter gleams under the soft overhead lights, reflecting the steam rising from the hot pots. In the foreground, a pair of chopsticks rests on a plate, hinting at the meal to come. The atmosphere is one of anticipation and warmth, inviting patrons to partake in the communal dining experience of a hot pot feast.\"'\n",
      "5.916666666666667: 'In a dimly lit restaurant, a plate of golden-brown French fries sits invitingly on a glossy black table. Beside it, a round tray holds an assortment of dumplings, their delicate wrappers hinting at the flavors within. The background is softly blurred, focusing the viewer's attention on the food. A small card with the number \"500\" is visible, perhaps indicating a table number or a special offer. The atmosphere is cozy and intimate, perfect for a casual dining experience.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with a playful expression and a cute beanie is in a bustling indoor area, possibly a shopping mall. She is surrounded by various storefronts and people. Next, a detailed description of a hot pot buffet in a dimly-lit restaurant is provided, with vibrant broths and an assortment of ingredients. Lastly, a plate of golden-brown French fries and a tray of dumplings are presented on a glossy black table in a cozy, intimate setting.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair and a playful expression is the focal point of this image. She is wearing a cozy, white beanie adorned with a cute animal face, adding a touch of whimsy to her appearance. The setting appears to be a bustling indoor area, possibly a shopping mall or a food court, with various storefronts and people in the background. The lighting is bright and inviting, highlighting the woman's features and the textures of her beanie. The overall mood of the image is cheerful and relaxed, capturing a candid moment in the woman's day.'\n",
      "1: 'In a dimly lit, cozy café, a plate of golden-brown french fries rests on a glossy black table. The fries are neatly arranged, their crispy edges glistening under the soft light. Beside the plate, a round, frosted cake adorned with red and white sprinkles adds a touch of sweetness to the scene. In the background, a small card with the number \"205\" stands out, perhaps indicating a table number or a special order. The atmosphere is warm and inviting, evoking a sense of comfort and indulgence.'\n",
      "5.916666666666667: 'In a bustling urban setting, a young woman with long, flowing brown hair and a gentle smile is the focal point. She dons a cozy, plush hat adorned with playful animal ears, adding a touch of whimsy to her appearance. The background is a blur of city life, with indistinct figures moving about, suggesting a lively atmosphere. Overlaid on the image is text in a casual, conversational tone, hinting at a personal narrative or reflection. The overall composition conveys a sense of warmth and everyday beauty amidst the hustle and bustle of city life.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with long brown hair and a playful beanie is in a busy indoor area, possibly a mall. She's in a cozy café with fries and a cake on a black table. Later, she's in a bustling city with a plush hat, surrounded by city life and a personal narrative.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair and a playful expression is the focal point of this image. She is wearing a cozy, white beanie adorned with a cute animal face, adding a touch of whimsy to her appearance. The setting appears to be a bustling indoor area, possibly a shopping mall or a food court, with various storefronts and people in the background. The lighting is bright and inviting, highlighting the woman's features and the textures of her beanie. The overall mood of the image is cheerful and relaxed, capturing a candid moment in the woman's day.'\n",
      "1: 'In a bustling urban setting, a young woman with long, flowing brown hair stands in front of a vibrant storefront. She dons a cozy, knitted hat adorned with playful animal ears, adding a touch of whimsy to her appearance. Her eyes, full of youthful energy, gaze directly into the camera, inviting the viewer into her world. The background is alive with the hustle and bustle of city life, with other people going about their day, adding depth and context to the scene. The warm, inviting glow of the store's lights contrasts with the cool urban tones, creating a captivating visual narrative.'\n",
      "5.916666666666667: 'In the heart of a bustling city, a young woman with long, flowing brown hair stands confidently in front of a vibrant storefront. She dons a whimsical, knitted hat adorned with playful panda ears, adding a touch of charm to her appearance. Her eyes sparkle with a hint of mischief as she winks playfully at the camera, her hand raised to form a peace sign. The store behind her is a riot of colors, filled with an array of intriguing items that hint at a world of creativity and imagination. The atmosphere is lively and inviting, capturing the essence of urban life and the joy of discovery.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with long brown hair and a playful beanie is in a busy indoor area, possibly a mall. She stands in front of a vibrant storefront, her eyes full of energy, as she gazes at the camera. She later winks playfully and raises a peace sign, surrounded by colorful items in a lively urban setting.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_984_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_984_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_984_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_984_3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'In the heart of a bustling city, a young woman with long, flowing brown hair and a radiant smile stands out. She's donned in a cozy white beanie adorned with playful animal ears, adding a touch of whimsy to her appearance. Her eyes sparkle with joy as she looks directly into the camera, her expression inviting and warm. The background is a blur of activity, with indistinct figures moving about, suggesting a lively public space. The lighting is soft and diffused, casting a gentle glow on her face and highlighting her features. The overall mood is cheerful and vibrant, capturing a moment of happiness in the midst of urban life.'\n",
      "1: 'In a bustling urban setting, a young woman with long, flowing brown hair and sparkling eyes stands out. She's donned in a cozy, knitted hat adorned with a playful panda face, adding a touch of whimsy to her appearance. She's dressed in a soft, pastel-colored sweater that complements her gentle demeanor. The background is a blur of city life, with the glow of neon signs and the hum of distant conversations, creating a lively yet intimate atmosphere. Her expression is one of quiet contentment, as if she's taking a moment to appreciate the simple beauty of her surroundings.'\n",
      "5.916666666666667: 'In the heart of a bustling city, a young woman with long, flowing brown hair stands confidently in front of a vibrant storefront. She dons a whimsical, knitted hat adorned with playful animal ears, adding a touch of charm to her appearance. Her eyes sparkle with mischief as she winks playfully at the camera, her hand raised to form a peace sign. The store behind her is alive with color and activity, featuring large, eye-catching advertisements and a variety of products displayed in the window. The atmosphere is lively and inviting, reflecting the energy of urban life.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with brown hair and a whimsical hat stands in a bustling city, smiling and looking at the camera. She's in a lively public space with blurred figures and soft lighting. She wears a pastel sweater and a panda hat, exuding a cheerful vibe. She stands confidently in front of a colorful storefront, winking playfully and forming a peace sign. The store is vibrant with advertisements and products.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'In the heart of a bustling city, a young woman with long, flowing brown hair and a radiant smile stands out. She's donned in a cozy white beanie adorned with playful animal ears, adding a touch of whimsy to her appearance. Her eyes sparkle with joy as she looks directly into the camera, her expression inviting and warm. The background is a blur of activity, with indistinct figures moving about, suggesting a lively public space. The lighting is soft and diffused, casting a gentle glow on her face and highlighting her features. The overall mood is cheerful and vibrant, capturing a moment of happiness in the midst of urban life.'\n",
      "1: 'In the heart of a bustling city, a young woman with long, flowing brown hair stands confidently in front of a vibrant storefront. She dons a whimsical white beanie adorned with playful black cat ears, adding a touch of whimsy to her appearance. Her eyes sparkle with mischief as she winks at the camera, her hand raised in a peace sign, embodying a carefree spirit. The store behind her is alive with color and activity, its large windows reflecting the hustle and bustle of the street. The atmosphere is one of youthful energy and urban charm, capturing a moment of joy and spontaneity in the midst of city life.'\n",
      "5.916666666666667: 'A young woman, adorned with a whimsical panda hat, gazes directly into the camera with a gentle smile. Her long, flowing hair cascades down her shoulders, complementing her soft, pastel-colored outfit. The background is a blur of indistinct figures and lights, suggesting a bustling, lively environment, possibly a shopping mall or a busy street. The atmosphere is warm and inviting, with a sense of youthful energy and joy.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with brown hair and a white beanie adorned with animal ears stands in a bustling city, smiling at the camera. She stands confidently in front of a colorful storefront, winking and raising a peace sign. She dons a panda hat and gazes with a gentle smile, surrounded by a lively, bustling environment.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'In the heart of a bustling city, a young woman with long, flowing brown hair and a radiant smile stands out. She's donned in a cozy white beanie adorned with playful animal ears, adding a touch of whimsy to her appearance. Her eyes sparkle with joy as she looks directly into the camera, her expression inviting and warm. The background is a blur of activity, with indistinct figures moving about, suggesting a lively public space. The lighting is soft and diffused, casting a gentle glow on her face and highlighting her features. The overall mood is cheerful and vibrant, capturing a moment of happiness in the midst of urban life.'\n",
      "1: 'A young woman, adorned with a whimsical panda hat, stands in a bustling subway station. Her long, flowing hair cascades down her shoulders, complementing her soft, pastel-colored jacket. The background is a blur of movement, with other commuters rushing by, their faces indistinct. The ambient lighting casts a warm glow on the scene, highlighting the woman's gentle smile as she gazes directly into the camera. The atmosphere is one of everyday life, captured in a moment of quiet amidst the hustle and bustle.'\n",
      "5.916666666666667: 'In the heart of a bustling city, a young woman with long, flowing brown hair stands confidently in front of a reflective glass wall. She dons a whimsical, knitted hat adorned with playful animal ears, adding a touch of charm to her appearance. Her eyes sparkle with a hint of mischief as she gives a thumbs-up sign, signaling her approval or perhaps her readiness for an adventure. The background is a blur of urban life, with indistinct figures moving about, suggesting the constant ebb and flow of city dwellers. Overlaid on the image is a text in a foreign language, adding an air of mystery and intrigue to the scene. The overall composition captures a moment of youthful exuberance amidst the hustle and bustle of city life.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with brown hair and a whimsical beanie stands in a bustling city, smiling at the camera. She's in a subway station, her hair flowing and pastel jacket complementing her panda hat. Later, she stands confidently in front of a glass wall, giving a thumbs-up, her hat adorned with animal ears, surrounded by the city's hustle and a foreign language text.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'In the heart of a bustling city, a young woman with long, flowing brown hair and a radiant smile stands out. She's donned in a cozy white beanie adorned with playful animal ears, adding a touch of whimsy to her appearance. Her eyes sparkle with joy as she looks directly into the camera, her expression inviting and warm. The background is a blur of activity, with indistinct figures moving about, suggesting a lively public space. The lighting is soft and diffused, casting a gentle glow on her face and highlighting her features. The overall mood is cheerful and vibrant, capturing a moment of happiness in the midst of urban life.'\n",
      "1: 'In the heart of a bustling city, a young woman with long, flowing brown hair stands in front of a large, ornate mirror. She is adorned in a cozy, white knitted hat with playful black spots, reminiscent of a beloved cartoon character. Her eyes sparkle with a gentle smile as she looks directly into the camera, exuding a sense of warmth and friendliness. The mirror behind her reflects the vibrant life of the city, with blurred figures of people going about their day, adding a dynamic backdrop to her serene presence. The text overlay in the image reads, \"妆画得很淡 可能和后面的我长得不太一样 不要在意,\" which translates to \"The makeup is very light, maybe the one behind me looks quite different, don't pay attention.\" This adds a layer of introspection to the scene, inviting viewers to ponder the contrast between appearances and reality.'\n",
      "5.916666666666667: 'A young woman, donning a whimsical white bear hat, ascends an escalator in a dimly lit subway station. She is clad in a soft lavender hoodie, her long hair cascading down her back. Beside her, a companion in a black hoodie follows, their figures casting elongated shadows on the metallic steps. The walls are adorned with a subtle pattern, and a faint glow emanates from the exit sign at the top of the escalator, guiding the way forward.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with brown hair and a white beanie stands in a bustling city, smiling at the camera. She poses in front of a mirror with a cartoon hat, reflecting the city's vibrant life. She then wears a bear hat and ascends an escalator in a subway station, her companion following closely.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_924_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_924_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_924_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_924_3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair and a gentle smile is the focal point of this image. She is wearing a cozy, knitted hat adorned with a playful panda face, adding a touch of whimsy to her appearance. Her makeup is subtle, enhancing her natural beauty without overpowering it. She is dressed in a soft, pastel-colored jacket that complements her overall look. The background is blurred, but it appears to be an indoor setting, possibly a public space like a train station or a shopping mall. The lighting is soft and diffused, casting a warm glow on her face and creating a serene atmosphere. The text overlay in the image reads, \"妆画得很淡 可能和后面长得不太一样 不要在意,\" which translates to \"The makeup is very light, maybe it looks different from what's behind, don't worry about it.\" This suggests a sense of self-acceptance and comfort with one's appearance.'\n",
      "1: 'In a bustling urban setting, a young woman with long, flowing brown hair and sparkling eyes stands out. She's donned in a cozy, knitted hat adorned with a playful panda face, adding a touch of whimsy to her appearance. She's dressed in a soft, pastel-colored sweater that complements her gentle demeanor. The background is a blur of city life, with the glow of neon signs and the hum of distant conversations, creating a lively yet intimate atmosphere. Her expression is one of quiet contentment, as if she's taking a moment to appreciate the simple beauty of her surroundings.'\n",
      "5.916666666666667: 'In the heart of a bustling city, a young woman with long, flowing brown hair stands confidently in front of a vibrant storefront. She dons a whimsical, knitted hat adorned with playful animal ears, adding a touch of charm to her appearance. Her eyes sparkle with mischief as she winks playfully at the camera, her hand raised to form a peace sign. The store behind her is alive with color and activity, featuring large, eye-catching advertisements and a variety of products displayed in the window. The atmosphere is lively and inviting, reflecting the energy of urban life.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with long brown hair and a panda hat smiles in a soft indoor setting, possibly a train station. She's content in a bustling urban environment, her pastel sweater blending with the neon lights. She stands confidently in front of a colorful storefront, playfully winking at the camera with a peace sign.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair and a gentle smile is the focal point of this image. She is wearing a cozy, knitted hat adorned with a playful panda face, adding a touch of whimsy to her appearance. Her makeup is subtle, enhancing her natural beauty without overpowering it. She is dressed in a soft, pastel-colored jacket that complements her overall look. The background is blurred, but it appears to be an indoor setting, possibly a public space like a train station or a shopping mall. The lighting is soft and diffused, casting a warm glow on her face and creating a serene atmosphere. The text overlay in the image reads, \"妆画得很淡 可能和后面长得不太一样 不要在意,\" which translates to \"The makeup is very light, maybe it looks different from what's behind, don't worry about it.\" This suggests a sense of self-acceptance and comfort with one's appearance.'\n",
      "1: 'In the heart of a bustling city, a young woman with long, flowing brown hair stands confidently in front of a vibrant storefront. She dons a whimsical white beanie adorned with playful black cat ears, adding a touch of whimsy to her appearance. Her eyes sparkle with mischief as she winks at the camera, her hand raised in a peace sign, embodying a carefree spirit. The store behind her is alive with color and activity, its large windows reflecting the hustle and bustle of the street. The atmosphere is one of youthful energy and urban charm, capturing a moment of joy and spontaneity in the midst of city life.'\n",
      "5.916666666666667: 'A young woman, adorned with a whimsical panda hat, gazes directly into the camera with a gentle smile. Her long, flowing hair cascades down her shoulders, complementing her soft, pastel-colored outfit. The background is a blur of indistinct figures and lights, suggesting a bustling, lively environment, possibly a shopping mall or a busy street. The atmosphere is warm and inviting, with a sense of youthful energy and joy.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with long brown hair and a panda hat smiles in a cozy indoor setting, possibly a train station or mall. She stands confidently in a bustling city with a whimsical beanie and black cat ears, winking at the camera. She gazes directly at the camera with a gentle smile in a lively environment, possibly a shopping mall or busy street.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair and a gentle smile is the focal point of this image. She is wearing a cozy, knitted hat adorned with a playful panda face, adding a touch of whimsy to her appearance. Her makeup is subtle, enhancing her natural beauty without overpowering it. She is dressed in a soft, pastel-colored jacket that complements her overall look. The background is blurred, but it appears to be an indoor setting, possibly a public space like a train station or a shopping mall. The lighting is soft and diffused, casting a warm glow on her face and creating a serene atmosphere. The text overlay in the image reads, \"妆画得很淡 可能和后面长得不太一样 不要在意,\" which translates to \"The makeup is very light, maybe it looks different from what's behind, don't worry about it.\" This suggests a sense of self-acceptance and comfort with one's appearance.'\n",
      "1: 'A young woman, adorned with a whimsical panda hat, stands in a bustling subway station. Her long, flowing hair cascades down her shoulders, complementing her soft, pastel-colored jacket. The background is a blur of movement, with other commuters rushing by, their faces indistinct. The ambient lighting casts a warm glow on the scene, highlighting the woman's gentle smile as she gazes directly into the camera. The atmosphere is one of everyday life, captured in a moment of quiet amidst the hustle and bustle.'\n",
      "5.916666666666667: 'In the heart of a bustling city, a young woman with long, flowing brown hair stands confidently in front of a reflective glass wall. She dons a whimsical, knitted hat adorned with playful animal ears, adding a touch of charm to her appearance. Her eyes sparkle with a hint of mischief as she gives a thumbs-up sign, signaling her approval or perhaps her readiness for an adventure. The background is a blur of urban life, with indistinct figures moving about, suggesting the constant ebb and flow of city dwellers. Overlaid on the image is a text in a foreign language, adding an air of mystery and intrigue to the scene. The overall composition captures a moment of youthful exuberance amidst the hustle and bustle of city life.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with long brown hair and a panda hat smiles in a blurred indoor setting, possibly a train station. She stands in a busy subway station, her hair flowing and pastel jacket visible. In a cityscape, she stands confidently in front of a glass wall, wearing a whimsical hat with animal ears, giving a thumbs-up.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair and a gentle smile is the focal point of this image. She is wearing a cozy, knitted hat adorned with a playful panda face, adding a touch of whimsy to her appearance. Her makeup is subtle, enhancing her natural beauty without overpowering it. She is dressed in a soft, pastel-colored jacket that complements her overall look. The background is blurred, but it appears to be an indoor setting, possibly a public space like a train station or a shopping mall. The lighting is soft and diffused, casting a warm glow on her face and creating a serene atmosphere. The text overlay in the image reads, \"妆画得很淡 可能和后面长得不太一样 不要在意,\" which translates to \"The makeup is very light, maybe it looks different from what's behind, don't worry about it.\" This suggests a sense of self-acceptance and comfort with one's appearance.'\n",
      "1: 'In the heart of a bustling city, a young woman with long, flowing brown hair stands in front of a large, ornate mirror. She is adorned in a cozy, white knitted hat with playful black spots, reminiscent of a beloved cartoon character. Her eyes sparkle with a gentle smile as she looks directly into the camera, exuding a sense of warmth and friendliness. The mirror behind her reflects the vibrant life of the city, with blurred figures of people going about their day, adding a dynamic backdrop to her serene presence. The text overlay in the image reads, \"妆画得很淡 可能和后面的我长得不太一样 不要在意,\" which translates to \"The makeup is very light, maybe the one behind me looks quite different, don't pay attention.\" This adds a layer of introspection to the scene, inviting viewers to ponder the contrast between appearances and reality.'\n",
      "5.916666666666667: 'A young woman, donning a whimsical white bear hat, ascends an escalator in a dimly lit subway station. She is clad in a soft lavender hoodie, her long hair cascading down her back. Beside her, a companion in a black hoodie follows, their figures casting elongated shadows on the metallic steps. The walls are adorned with a subtle pattern, and a faint glow emanates from the exit sign at the top of the escalator, guiding the way forward.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with long brown hair and a panda hat smiles in a blurred indoor setting, reflecting self-acceptance. She stands in a city with a cartoon hat, looking into the camera with a warm smile. On an escalator in a subway station, she wears a bear hat and a lavender hoodie, with a companion beside her.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_774_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_774_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_774_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_774_3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair and a playful expression is the focal point of this image. She is wearing a cozy, white beanie adorned with a cute animal face, adding a touch of whimsy to her appearance. The setting appears to be a bustling indoor area, possibly a shopping mall or a food court, with various storefronts and people in the background. The lighting is bright and inviting, highlighting the woman's features and the textures of her beanie. The overall mood of the image is cheerful and relaxed, capturing a candid moment in the woman's day.'\n",
      "1: 'In a bustling urban setting, a young woman with long, flowing brown hair and sparkling eyes stands out. She's donned in a cozy, knitted hat adorned with a playful panda face, adding a touch of whimsy to her appearance. She's dressed in a soft, pastel-colored sweater that complements her gentle demeanor. The background is a blur of city life, with the glow of neon signs and the hum of distant conversations, creating a lively yet intimate atmosphere. Her expression is one of quiet contentment, as if she's taking a moment to appreciate the simple beauty of her surroundings.'\n",
      "5.916666666666667: 'In the heart of a bustling city, a young woman with long, flowing brown hair stands confidently in front of a vibrant storefront. She dons a whimsical, knitted hat adorned with playful animal ears, adding a touch of charm to her appearance. Her eyes sparkle with mischief as she winks playfully at the camera, her hand raised to form a peace sign. The store behind her is alive with color and activity, featuring large, eye-catching advertisements and a variety of products displayed in the window. The atmosphere is lively and inviting, reflecting the energy of urban life.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with long brown hair and a playful beanie is in a busy indoor area, possibly a mall. She's wearing a pastel sweater and looking content. Later, she stands confidently in front of a colorful store, winking playfully at the camera with her hand raised in a peace sign.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair and a playful expression is the focal point of this image. She is wearing a cozy, white beanie adorned with a cute animal face, adding a touch of whimsy to her appearance. The setting appears to be a bustling indoor area, possibly a shopping mall or a food court, with various storefronts and people in the background. The lighting is bright and inviting, highlighting the woman's features and the textures of her beanie. The overall mood of the image is cheerful and relaxed, capturing a candid moment in the woman's day.'\n",
      "1: 'In the heart of a bustling city, a young woman with long, flowing brown hair stands confidently in front of a vibrant storefront. She dons a whimsical white beanie adorned with playful black cat ears, adding a touch of whimsy to her appearance. Her eyes sparkle with mischief as she winks at the camera, her hand raised in a peace sign, embodying a carefree spirit. The store behind her is alive with color and activity, its large windows reflecting the hustle and bustle of the street. The atmosphere is one of youthful energy and urban charm, capturing a moment of joy and spontaneity in the midst of city life.'\n",
      "5.916666666666667: 'A young woman, adorned with a whimsical panda hat, gazes directly into the camera with a gentle smile. Her long, flowing hair cascades down her shoulders, complementing her soft, pastel-colored outfit. The background is a blur of indistinct figures and lights, suggesting a bustling, lively environment, possibly a shopping mall or a busy street. The atmosphere is warm and inviting, with a sense of youthful energy and joy.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with long brown hair and a playful beanie is in a busy indoor area, possibly a mall. She stands confidently in a city with vibrant storefronts, winking at the camera. She then wears a panda hat and smiles gently, surrounded by a lively, bustling environment.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair and a playful expression is the focal point of this image. She is wearing a cozy, white beanie adorned with a cute animal face, adding a touch of whimsy to her appearance. The setting appears to be a bustling indoor area, possibly a shopping mall or a food court, with various storefronts and people in the background. The lighting is bright and inviting, highlighting the woman's features and the textures of her beanie. The overall mood of the image is cheerful and relaxed, capturing a candid moment in the woman's day.'\n",
      "1: 'A young woman, adorned with a whimsical panda hat, stands in a bustling subway station. Her long, flowing hair cascades down her shoulders, complementing her soft, pastel-colored jacket. The background is a blur of movement, with other commuters rushing by, their faces indistinct. The ambient lighting casts a warm glow on the scene, highlighting the woman's gentle smile as she gazes directly into the camera. The atmosphere is one of everyday life, captured in a moment of quiet amidst the hustle and bustle.'\n",
      "5.916666666666667: 'In the heart of a bustling city, a young woman with long, flowing brown hair stands confidently in front of a reflective glass wall. She dons a whimsical, knitted hat adorned with playful animal ears, adding a touch of charm to her appearance. Her eyes sparkle with a hint of mischief as she gives a thumbs-up sign, signaling her approval or perhaps her readiness for an adventure. The background is a blur of urban life, with indistinct figures moving about, suggesting the constant ebb and flow of city dwellers. Overlaid on the image is a text in a foreign language, adding an air of mystery and intrigue to the scene. The overall composition captures a moment of youthful exuberance amidst the hustle and bustle of city life.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with long brown hair and a playful beanie is in a busy indoor area, possibly a mall. She stands in a subway station with a panda hat, surrounded by bustling commuters. In a city, she confidently poses in front of a glass wall, wearing a whimsical knitted hat with animal ears, her eyes sparkling with mischief.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair and a playful expression is the focal point of this image. She is wearing a cozy, white beanie adorned with a cute animal face, adding a touch of whimsy to her appearance. The setting appears to be a bustling indoor area, possibly a shopping mall or a food court, with various storefronts and people in the background. The lighting is bright and inviting, highlighting the woman's features and the textures of her beanie. The overall mood of the image is cheerful and relaxed, capturing a candid moment in the woman's day.'\n",
      "1: 'In the heart of a bustling city, a young woman with long, flowing brown hair stands in front of a large, ornate mirror. She is adorned in a cozy, white knitted hat with playful black spots, reminiscent of a beloved cartoon character. Her eyes sparkle with a gentle smile as she looks directly into the camera, exuding a sense of warmth and friendliness. The mirror behind her reflects the vibrant life of the city, with blurred figures of people going about their day, adding a dynamic backdrop to her serene presence. The text overlay in the image reads, \"妆画得很淡 可能和后面的我长得不太一样 不要在意,\" which translates to \"The makeup is very light, maybe the one behind me looks quite different, don't pay attention.\" This adds a layer of introspection to the scene, inviting viewers to ponder the contrast between appearances and reality.'\n",
      "5.916666666666667: 'A young woman, donning a whimsical white bear hat, ascends an escalator in a dimly lit subway station. She is clad in a soft lavender hoodie, her long hair cascading down her back. Beside her, a companion in a black hoodie follows, their figures casting elongated shadows on the metallic steps. The walls are adorned with a subtle pattern, and a faint glow emanates from the exit sign at the top of the escalator, guiding the way forward.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with brown hair and a playful beanie is in a busy indoor area, possibly a mall. She stands in front of a large mirror in a city setting, smiling warmly at the camera. She wears a white knitted hat with black spots and a lavender hoodie, ascending an escalator in a subway station with a companion.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_4.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'A bowl filled with a hearty soup sits on a wooden table, its vibrant yellow hue contrasting with the muted tones of the surroundings. The soup is brimming with chunks of tofu and flecks of green herbs, creating a sense of warmth and comfort. A pair of yellow chopsticks rests on the side of the bowl, their color echoing that of the bowl itself. In the background, a person's hands can be seen, suggesting the presence of a diner ready to enjoy their meal. The overall scene evokes a cozy, homely atmosphere, inviting the viewer to partake in the simple pleasure of enjoying a bowl of soup.'\n",
      "5.916666666666667: 'A long prompt for generating a high-quality image based on the provided photograph could be:\n",
      "\n",
      "\"Create a vibrant and appetizing image of freshly cooked dumplings, served on two bright yellow plates. The dumplings should have a golden-brown crust, indicating they have been expertly fried to perfection. One plate should have dumplings garnished with black sesame seeds, while the other should be sprinkled with green herbs, possibly chives or scallions, adding a pop of color and hinting at a savory flavor. The plates are placed on a warm-toned wooden table, which complements the golden hues of the dumplings. In the background, there should be a blurred figure of a person, suggesting a casual dining atmosphere. The image should evoke a sense of warmth and comfort, inviting viewers to imagine the taste and texture of these delicious dumplings. The overall composition should be balanced, with the focus on the dumplings, and the background elements softly out of focus to keep the viewer's attention on the main subject.\"'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment, one with a pink bow and the other with a red ribbon, in a cozy indoor setting. A bowl of soup with tofu and herbs sits on a wooden table, inviting a sense of warmth. A prompt for an image of dumplings on yellow plates with garnishes and a blurred figure in the background suggests a casual dining atmosphere.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'A long prompt for generating a high-quality image based on the provided photograph could be:\n",
      "\n",
      "\"Create a vibrant and appetizing image of freshly cooked steamed buns, known as \"小杨生煎\" (Xiao Yang Sheng Jian), served on bright yellow plates. The buns should have a slightly golden-brown crust with visible green herbs sprinkled on top, indicating a savory flavor. The plates are placed on a warm-toned wooden table, enhancing the cozy and inviting atmosphere of a traditional Chinese dim sum restaurant. The background should be softly blurred to focus attention on the steamed buns, emphasizing their texture and appealing appearance. The lighting should be soft and warm, casting gentle shadows and highlighting the steam rising from the hot buns, creating a sense of freshness and warmth. The overall composition should evoke a sense of comfort and culinary delight, inviting viewers to imagine the taste and aroma of these delicious steamed treats.\"'\n",
      "5.916666666666667: 'A young girl with long, wavy brown hair tied in pigtails with red ribbons stands in a cozy, well-lit room. She is dressed in a charming pink and white checkered dress with a ruffled collar, exuding a sense of innocence and playfulness. Behind her, a collection of elegant dresses hangs on a rack, suggesting a setting related to fashion or clothing. The atmosphere is warm and inviting, with soft natural light filtering through a window, casting gentle shadows and highlighting the girl's cheerful expression. The text overlay in the image reads, \"吃完啦 来逛一下小裙子,\" which translates to \"Finished eating, let's go shopping for some little dresses,\" adding a narrative element to the scene.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. They are dressed in pastel-colored outfits, reflecting innocence and playfulness. A young girl in a pink and white checkered dress stands in a well-lit room, surrounded by elegant dresses, suggesting a fashion-related setting.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'A young girl with long brown hair tied in pigtails, adorned with pink bows, stands in a room filled with hanging dresses. She wears a white blouse with lace details and a red and white checkered skirt. Her lips are painted a vibrant red, and she gazes directly into the camera with a playful expression. The room is softly lit, creating a warm and inviting atmosphere. Text on the image reads, \"吃完啦 来逛一下小裙子,\" which translates to \"Finished eating, let's take a look at the little dresses.\"'\n",
      "5.916666666666667: 'A young girl with long, wavy brown hair adorned with a red bow stands in a bustling shopping mall. She wears a pink and white striped dress with a ruffled collar, her lips painted a vibrant red. The mall is alive with activity; people walk by, some stopping to look at the colorful dresses displayed on mannequins in the background. The lighting is bright, casting a warm glow over the scene. The girl gazes directly into the camera, her eyes reflecting a sense of wonder and curiosity.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. A girl in a room filled with dresses gazes into the camera after eating. In a shopping mall, another girl with a pink and white dress and a red bow stands amidst bustling activity, looking curious and playful.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'A young girl with long, wavy brown hair adorned with a red bow stands in a bustling shopping mall. She is dressed in a pink and white striped dress with a ruffled collar, her eyes sparkling with excitement. The mall is filled with people, some of whom are dressed in elaborate costumes, suggesting a cosplay event. The background is a blur of activity, with bright lights and colorful displays adding to the lively atmosphere. The girl's cheerful expression and the vibrant surroundings create a sense of joy and wonder.'\n",
      "5.916666666666667: 'A bustling vintage clothing store, filled with an array of colorful garments hanging on racks. The shop is adorned with whimsical decorations, including a large heart-shaped balloon and playful accessories like hats and scarves. The lighting casts a warm glow over the merchandise, highlighting the textures and patterns of the fabrics. Shelves in the background are stocked with additional items, creating a sense of depth and abundance. The overall atmosphere is one of nostalgia and charm, inviting customers to explore the treasures within.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. A girl with a red bow in her hair stands in a bustling shopping mall, excited by the cosplay event. The scene transitions to a vintage clothing store filled with colorful garments and whimsical decorations, creating a nostalgic and charming atmosphere.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'A bustling vintage clothing store, filled with an array of colorful dresses and accessories. The shelves are adorned with heart-shaped decorations, adding a touch of whimsy to the nostalgic atmosphere. In the foreground, a charming hat rests on a decorative plate, inviting customers to explore the treasures within. The text \"啊 天堂\" is prominently displayed, evoking a sense of wonder and discovery.'\n",
      "5.916666666666667: 'In the heart of a quaint boutique, an array of exquisite dresses adorns the mannequins, each more enchanting than the last. The central figure, a mannequin dressed in a pastel pink gown, stands out with its voluminous skirt and delicate lace details. To its right, another mannequin, adorned in a soft green dress, adds a touch of vintage charm with its ruffled sleeves and intricate bodice. On the left, a third mannequin, dressed in a pristine white gown, catches the eye with its sheer fabric and floral embellishments. The background is filled with racks of clothing and accessories, creating a sense of depth and abundance. The atmosphere is one of whimsy and elegance, inviting customers to step into a world of fairy-tale fashion.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. They are dressed in pastel-colored outfits, reflecting innocence and playfulness. Next, a bustling vintage clothing store with heart-shaped decorations and a display of \"啊 天堂\" captures the essence of wonder and discovery. Finally, a quaint boutique showcases an array of enchanting dresses on mannequins, each more captivating than the last, creating a whimsical and elegant atmosphere.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1321_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1321_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1321_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1321_3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1321_4.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair, wearing a cozy white knitted hat with playful animal ears, stands on a moving walkway in a modern subway station. She is dressed in a light purple jacket, her eyes gently closed, and a content smile on her face. The background features sleek, metallic surfaces and the soft glow of ambient lighting, creating a serene atmosphere. The text overlay reads, \"吃饱了 我困了 鸣鸣鸣,\" adding a touch of whimsy to the scene.'\n",
      "1: 'A young woman, clad in a cozy white hoodie and a whimsical bear hat, ascends an escalator in a bustling subway station. Her companion, dressed in a sleek black jacket, follows closely behind her. The metallic sheen of the escalator steps gleams under the fluorescent lights, reflecting the hustle and bustle of city life. The walls are adorned with a pattern of tiles, adding a touch of urban charm to the scene. As they move upwards, the anticipation of reaching their destination fills the air, encapsulating the everyday journey of city dwellers.'\n",
      "5.916666666666667: 'A young woman, adorned with a whimsical white bear hat, ascends an escalator in a bustling subway station. She is clad in a casual white hoodie, her long dark hair cascading down her back. In her right hand, she clutches a vibrant red bag, adding a pop of color to her otherwise muted attire. The station is alive with the hum of activity, the metallic gleam of the escalator steps reflecting the ambient light. The background is a blur of indistinct figures, each absorbed in their own world, creating a dynamic tapestry of urban life.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with long brown hair and a white knitted hat stands on a moving walkway in a modern subway station, eyes closed, smiling contently. She wears a purple jacket and the station is serene with sleek metallic surfaces and ambient lighting. She then wears a white hoodie and bear hat, ascending an escalator with a companion in a black jacket. The escalator steps gleam under fluorescent lights, reflecting the bustling city life. She continues to ascend, clutching a red bag, surrounded by the hum of activity and a blur of indistinct figures.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair, wearing a cozy white knitted hat with playful animal ears, stands on a moving walkway in a modern subway station. She is dressed in a light purple jacket, her eyes gently closed, and a content smile on her face. The background features sleek, metallic surfaces and the soft glow of ambient lighting, creating a serene atmosphere. The text overlay reads, \"吃饱了 我困了 鸣鸣鸣,\" adding a touch of whimsy to the scene.'\n",
      "1: 'A young woman, adorned with a whimsical teddy bear hat, ascends an escalator in a bustling subway station. Clad in a cozy white hoodie, she carries a black shoulder bag, her long hair cascading down her back. The station is alive with the hum of commuters, each absorbed in their own world. The tiled walls reflect the soft glow of fluorescent lights, casting a warm hue over the scene. As she moves upward, she seems lost in thought, perhaps contemplating the day ahead or reminiscing about past adventures. The image captures a moment of quiet introspection amidst the constant ebb and flow of city life.'\n",
      "5.916666666666667: 'A young woman with long, flowing brown hair is seated on an escalator, her eyes gently closed as if she's taking a moment to rest. She's wearing a cozy, fluffy white beanie adorned with a cute animal face, adding a playful touch to her appearance. She's dressed in a soft, pastel-colored jacket that complements her serene demeanor. The metallic sheen of the escalator steps reflects the ambient light, creating a sense of calm and tranquility. The background is softly blurred, focusing the viewer's attention on her peaceful expression.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with long brown hair and a white knitted hat stands on a moving walkway in a modern subway station, eyes closed, smiling contently amidst sleek surfaces and ambient lighting. She ascends an escalator, lost in thought, her hair flowing, as the station buzzes with activity. Later, she sits on an escalator, eyes gently closed, wearing a fluffy white beanie, serene and peaceful.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair, wearing a cozy white knitted hat with playful animal ears, stands on a moving walkway in a modern subway station. She is dressed in a light purple jacket, her eyes gently closed, and a content smile on her face. The background features sleek, metallic surfaces and the soft glow of ambient lighting, creating a serene atmosphere. The text overlay reads, \"吃饱了 我困了 鸣鸣鸣,\" adding a touch of whimsy to the scene.'\n",
      "1: 'A young woman with long, flowing brown hair, wearing a cozy white beanie adorned with a cute animal face, sits comfortably on an escalator. She is dressed in a soft pink jacket, and her eyes are gently closed, suggesting she is either resting or lost in thought. The metallic sheen of the escalator steps reflects the ambient light, adding a sense of depth to the scene. The background is softly blurred, focusing the viewer's attention on the woman's peaceful demeanor. The overall atmosphere is one of tranquility and quiet introspection.'\n",
      "5.916666666666667: 'A young woman with long, flowing brown hair and bright, expressive eyes is captured in a candid moment on an escalator. She's wearing a cozy, knitted hat adorned with playful animal ears, adding a touch of whimsy to her appearance. Dressed in a soft, pastel-colored jacket, she exudes a sense of warmth and comfort. The background is blurred, focusing the viewer's attention on her, but the metallic sheen of the escalator steps and the ambient lighting suggest an urban setting. The text overlay in a casual, handwritten font adds a personal touch, hinting at a narrative or emotion behind the image.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with long brown hair and a white knitted hat adorned with animal ears stands on a moving walkway in a modern subway station, her eyes gently closed, smiling contently amidst sleek, metallic surfaces and ambient lighting. She sits on an escalator, eyes closed, in a soft pink jacket, reflecting the tranquil atmosphere. In a candid moment, she's captured on an escalator, her hat with animal ears adding whimsy, in a pastel-colored jacket, surrounded by the urban setting's metallic sheen and ambient lighting.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair, wearing a cozy white knitted hat with playful animal ears, stands on a moving walkway in a modern subway station. She is dressed in a light purple jacket, her eyes gently closed, and a content smile on her face. The background features sleek, metallic surfaces and the soft glow of ambient lighting, creating a serene atmosphere. The text overlay reads, \"吃饱了 我困了 鸣鸣鸣,\" adding a touch of whimsy to the scene.'\n",
      "1: 'A young woman with long, flowing brown hair and bright, expressive eyes is captured in a candid moment on an escalator. She's wearing a cozy, knitted hat adorned with playful animal ears, adding a touch of whimsy to her appearance. Her outfit is casual yet stylish, featuring a light-colored jacket layered over a black top. The background is softly blurred, emphasizing her as the focal point, while the metallic sheen of the escalator steps adds a modern, urban feel to the scene. The lighting is soft and diffused, casting gentle shadows and highlighting her features with a warm, inviting glow.'\n",
      "5.916666666666667: 'In a whimsical, fairy-tale-like setting, two young girls stand side by side, adorned in elaborate costumes reminiscent of a fantasy world. The girl on the left sports a blonde wig with a delicate pink bow, her eyes sparkling with excitement. Beside her, the girl on the right has long, dark hair and wears a headpiece shaped like cat ears, adding a playful touch to her appearance. They are both dressed in pastel-colored outfits with intricate details, suggesting they are part of a special event or celebration. The background is softly blurred, focusing the viewer's attention on the girls, who seem to be enjoying a moment of joy and camaraderie. The overall atmosphere is one of enchantment and youthful exuberance.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with long brown hair and a knitted hat stands on a subway walkway, smiling contentedly. She's followed by a candid shot of the same woman on an escalator, her features highlighted by soft lighting. Next, two girls in fantasy costumes stand side by side, their excitement and camaraderie evident.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: 'A young woman with long, flowing brown hair, wearing a cozy white knitted hat with playful animal ears, stands on a moving walkway in a modern subway station. She is dressed in a light purple jacket, her eyes gently closed, and a content smile on her face. The background features sleek, metallic surfaces and the soft glow of ambient lighting, creating a serene atmosphere. The text overlay reads, \"吃饱了 我困了 鸣鸣鸣,\" adding a touch of whimsy to the scene.'\n",
      "1: 'In the heart of a whimsical forest, two young girls stand side by side, their eyes sparkling with excitement. The girl on the left, with her blonde hair cascading down like a waterfall, wears a delicate pink headband adorned with white lace and fluffy white pom-poms. Her companion on the right, with her dark brown hair flowing like a river, sports a headband shaped like animal ears, adding a playful touch to her look. Both girls are dressed in pastel-colored dresses, their outfits complementing the soft hues of the surrounding foliage. The forest around them is alive with the gentle rustling of leaves and the distant chirping of birds, creating a serene and enchanting atmosphere. Their smiles are wide and genuine, reflecting the joy they feel in this magical setting.'\n",
      "5.916666666666667: 'In the heart of a whimsical forest, two young girls stand side by side, their eyes sparkling with excitement. The girl on the left, with her blonde hair cascading down like a waterfall, wears a delicate pink headband adorned with white lace and fluffy white pom-poms. Her companion on the right, with her long brown hair flowing like a river, sports a charming brown headband embellished with playful animal ears. Both girls are dressed in vibrant, colorful outfits that seem to glow with a magical light. The forest around them is alive with the sounds of rustling leaves and chirping birds, creating a serene and enchanting backdrop for their adventure. Their smiles are wide and genuine, reflecting the joy and wonder they feel in this fantastical world.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:A young woman with long brown hair and a white knitted hat stands on a moving walkway in a modern subway station, smiling contentedly. Two girls in pastel dresses and headbands explore a whimsical forest, their excitement evident. The forest comes alive with rustling leaves and bird chirps, enhancing their magical adventure.\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511_4.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: '\"Two young women, adorned with whimsical animal ear headbands, stand side by side in a cozy, warmly lit room. The woman on the left, with her blonde hair cascading down her shoulders, wears a delicate pink lace headband, while the woman on the right sports a brown and white striped headband with playful cat ears. Both are dressed in soft, pastel-colored outfits, exuding a sense of youthful charm and elegance. The background is softly blurred, focusing the viewer's attention on the two friends, who seem to be enjoying a moment of shared joy and camaraderie. The overall atmosphere is one of warmth, friendship, and the simple pleasures of life.\"'\n",
      "5.916666666666667: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of camaraderie. The woman on the left, with her blonde hair cascading in soft waves, gazes directly into the camera, her eyes sparkling with joy. Her companion, with dark brown hair and a warm smile, looks slightly away, her attention seemingly caught by something off-frame. They are dressed in pastel-hued outfits, evoking a sense of innocence and playfulness. The background is softly blurred, hinting at an indoor setting with warm, ambient lighting that enhances the cozy atmosphere. The text overlay adds a personal touch, suggesting a narrative or a shared experience between the two friends.\"'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share joyful moments in a cozy, warmly lit room. They wear pastel-colored outfits, their expressions bright and cheerful. The background is softly blurred, emphasizing their camaraderie and youthful exuberance.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: '\"Two friends, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with blonde hair cascading in soft curls, wears a delicate pink bow, while the one on the right, with long brown hair, sports a red ribbon. They stand against a backdrop of a cozy, warmly lit room, evoking a sense of homeliness and comfort. Their smiles radiate warmth, and the text above them reads, '是不是和前面长得不一样了 可以吃啥啥不胖' and 'jiang~第二天 我们精致滴打扮好啦', adding a touch of personal narrative to the scene.\"'\n",
      "5.916666666666667: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of playful camaraderie. The one on the left, with blonde hair cascading down her shoulders, sports a pink bow, while her companion on the right, with dark hair, wears a red ribbon. They are dressed in pastel-colored outfits, evoking a sense of youthful innocence. The background is softly blurred, hinting at an indoor setting with warm, ambient lighting. Their expressions are cheerful, and they seem to be enjoying each other's company, creating an atmosphere of joy and friendship.\"'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share joyful camaraderie, adorned in pastel outfits. They stand in a cozy, warmly lit room, their expressions bright and cheerful. They seem to be enjoying each other's company, creating an atmosphere of joy and friendship.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'In the heart of a cozy café, two young women, adorned in whimsical animal-themed headbands, share a moment of joy. The woman on the left, with her blonde hair cascading down, is playfully making a peace sign with her hand, her eyes sparkling with delight. Her companion on the right, with her long, dark hair, gazes at the camera with a gentle smile, her red lips slightly parted. They are both dressed in pastel-colored outfits, adding to the soft, dreamy atmosphere of the scene. The background is softly blurred, focusing the viewer's attention on the two friends, but one can still make out the warm, inviting ambiance of the café. The lighting is soft and diffused, casting a gentle glow on their faces, enhancing the overall sense of warmth and camaraderie.'\n",
      "5.916666666666667: '\"Two young women, adorned with whimsical headbands and playful accessories, share a moment of camaraderie in a cozy, warmly lit room. The blonde woman, with her hair cascading down in soft waves, and the brunette, with her hair styled in loose curls, both exude a sense of youthful energy and joy. Their outfits, a blend of pastel colors and delicate patterns, complement their cheerful expressions. The background, softly blurred, hints at a domestic setting, perhaps a living room or a café, adding to the intimate and relaxed atmosphere of the scene. The text overlay, written in a casual, friendly font, adds a personal touch, inviting the viewer to share in their lighthearted conversation.\"'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share joyful moments in a cozy setting. They are dressed in pastel-colored outfits, surrounded by a warm, inviting atmosphere. The scene captures their camaraderie and youthful exuberance, with expressions of happiness and light-heartedness.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'In the heart of a cozy café, two friends, adorned in whimsical animal-themed headbands, share a moment of joy. The blonde friend, with her hair cascading in soft waves, is dressed in a delicate white lace dress, while her companion, with long dark hair, wears a charming pink and white outfit. Their smiles radiate warmth as they pose for the camera, their hands playfully raised in a peace sign. The background is a blur of warm tones, hinting at the inviting ambiance of the café. The scene is a snapshot of friendship and fun, capturing the essence of a delightful day spent together.'\n",
      "5.916666666666667: 'In the heart of a bustling city, two young women stand side by side, their vibrant outfits contrasting against the urban backdrop. The woman on the left, with her blonde hair cascading down her shoulders, dons a pink and white headband adorned with delicate lace and fluffy white pom-poms. Her eyes sparkle with excitement as she gazes directly into the camera, her smile radiating warmth and joy.\n",
      "\n",
      "Beside her, the woman on the right, with her long, dark hair flowing freely, sports a brown and beige headband embellished with intricate patterns and a charming bow. Her lips are painted a bold orange, adding a pop of color to her serene expression as she looks off to the side, lost in thought.\n",
      "\n",
      "The background is a blur of city life, with the hustle and bustle of pedestrians and the hum of distant conversations creating a lively atmosphere. Despite the chaos, the two women remain the focal point of the image, their unique styles and personalities shining through in this candid moment captured in time.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share joy in a cozy indoor setting, possibly a café. They wear pastel-colored outfits and have bright expressions. In a café, they pose playfully with peace signs. In a bustling city, they stand side by side, their vibrant outfits contrasting with the urban backdrop.\n",
      "caption_summary_prompt:We extracted several frames from this video and described\n",
      "each frame using an image understanding model, stored in the dictionary variable ‘image_captions: Dict[str: str]‘.\n",
      "In ‘image_captions‘, the key is the second at which the image appears in the video, and the value is a detailed description\n",
      "of the image at that moment. Please describe the content of this video in as much detail as possible, based on the\n",
      "information provided by ‘image_captions‘, including the objects, scenery, animals, characters, and camera\n",
      "movements within the video. \n",
      " image_captions=0: '\"Two young women, adorned with whimsical animal ear headbands, share a moment of joy and camaraderie. The one on the left, with her blonde hair cascading down, wears a delicate pink bow, while the one on the right, sporting dark hair, has a red ribbon in her hair. They are dressed in pastel-colored outfits, evoking a sense of innocence and playfulness. The background, though blurred, hints at a cozy indoor setting, possibly a café or a quaint room, adding to the intimate atmosphere of their shared experience. Their expressions are bright and cheerful, reflecting the light-heartedness of their encounter. The scene is a snapshot of friendship and youthful exuberance, captured in a moment of pure, unadulterated happiness.\"'\n",
      "1: 'In the heart of a bustling city, two young women stand side by side, their eyes sparkling with excitement. The woman on the left, with her blonde hair cascading down like a waterfall, is adorned with a whimsical headpiece that resembles a cute animal, complete with fluffy white ears and a delicate pink bow. Her companion on the right, with her long, flowing brown hair, sports a similar headpiece, but with a touch of elegance, featuring intricate patterns and a vibrant red ribbon. Both women are dressed in charming outfits that evoke a sense of nostalgia, reminiscent of a bygone era. The background is a blur of urban life, with the hustle and bustle of the city fading into the distance, allowing the focus to remain on these two captivating figures. Their smiles are infectious, radiating warmth and joy, as if they are about to embark on an exciting adventure together. This moment, frozen in time, captures the essence of friendship and the joy of shared experiences.'\n",
      "5.916666666666667: 'A young girl with long, wavy brown hair adorned with pink flowers in her hair stands in a bustling market. She wears a delicate pink and white checkered dress with a ruffled collar, reminiscent of a classic doll's outfit. Her large, expressive eyes gaze directly into the camera, and her lips are painted with a soft shade of pink lipstick. The background is filled with the vibrant colors and activity of the market, with stalls and people adding to the lively atmosphere. The lighting is bright and natural, highlighting the girl's features and the textures of her hair and dress.'\n",
      "\n",
      "\n",
      "You should output your summary directly, and not mention\n",
      "variables like ‘image_captions‘ in your response.\n",
      "Do not include ‘\\n’ and the word ’video’ in your response.\n",
      "Do not use introductory phrases such as: \"The video presents\", \"The video depicts\", \"This video showcases\",\n",
      "\"The video captures\" and so on.\n",
      " Please start the description with the video content directly, such as \"A man\n",
      "first sits in a chair, then stands up and walks to the kitchen....\"\n",
      " Do not use phrases like: \"as the video\n",
      "progressed\" and \"Throughout the video\".\n",
      " Please describe  the content of the video and the changes that occur, in\n",
      "chronological order.\n",
      " Please keep the description of this video within 100 English words.\n",
      "caption_summary_text:Two young women with animal ear headbands share a joyful moment in a cozy indoor setting, possibly a café. They are dressed in pastel-colored outfits, reflecting innocence and playfulness. In a bustling city, they stand side by side, excited and adorned with whimsical headpieces, their smiles infectious. A young girl in a bustling market stands with pink flowers in her hair, wearing a classic doll's outfit, her eyes expressive and lips painted pink.\n"
     ]
    }
   ],
   "source": [
    "split_video_with_chunk('/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站/','test_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1ab722d-79ad-40f8-bead-9329982e33c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_542.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_542.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_697.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_697.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1268.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1268.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1268.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1321.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1321.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1321.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1139.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1139.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1139.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1125.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1125.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1125.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1029.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1029.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1029.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1029.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1029.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1029.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1029.0_4.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_774.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_774.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_774.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_774.0_4.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_984.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_984.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_984.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_984.0_4.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_924.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_924.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_924.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_924.0_4.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_774.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_774.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_774.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_774.0_4.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_4.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_5.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1321.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1321.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1321.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1321.0_4.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1321.0_5.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_4.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([71, 3, 960, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_1//scene_chunks/videos/chunk_1511.0_5.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([72, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_11//scene_chunks/videos/chunk_0.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([72, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_11//scene_chunks/videos/chunk_0.0_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_12//scene_chunks/videos/chunk_253.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_12//scene_chunks/videos/chunk_253.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_12//scene_chunks/videos/chunk_253.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_12//scene_chunks/videos/chunk_253.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_12//scene_chunks/videos/chunk_279.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_12//scene_chunks/videos/chunk_279.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_12//scene_chunks/videos/chunk_364.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_12//scene_chunks/videos/chunk_364.0_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([85, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_14//scene_chunks/videos/chunk_155.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([85, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_14//scene_chunks/videos/chunk_155.0_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_15//scene_chunks/videos/chunk_97.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_15//scene_chunks/videos/chunk_97.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_15//scene_chunks/videos/chunk_187.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_15//scene_chunks/videos/chunk_187.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 720, 1280])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_16//scene_chunks/videos/chunk_0.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 720, 1280])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_16//scene_chunks/videos/chunk_0.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 720, 1280])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_16//scene_chunks/videos/chunk_0.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 720, 1280])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_16//scene_chunks/videos/chunk_0.0_4.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([82, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_17//scene_chunks/videos/chunk_143.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([82, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_17//scene_chunks/videos/chunk_143.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([82, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_17//scene_chunks/videos/chunk_143.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([82, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_17//scene_chunks/videos/chunk_143.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([82, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_17//scene_chunks/videos/chunk_143.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([82, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_17//scene_chunks/videos/chunk_143.0_4.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_19//scene_chunks/videos is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_19//scene_chunks/videos\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_19//scene_chunks/labels is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_19//scene_chunks/labels\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_19//scene_chunks/videos/chunk_77.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_19//scene_chunks/videos/chunk_77.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_19//scene_chunks/videos/chunk_100.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_19//scene_chunks/videos/chunk_100.0_2.mp4\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_2//scene_chunks/videos is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_2//scene_chunks/videos\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_2//scene_chunks/labels is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_2//scene_chunks/labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_2//scene_chunks/videos/chunk_261.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_2//scene_chunks/videos/chunk_261.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_2//scene_chunks/videos/chunk_261.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_2//scene_chunks/videos/chunk_261.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_2//scene_chunks/videos/chunk_261.0_3.mp4\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_20//scene_chunks/videos is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_20//scene_chunks/videos\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_20//scene_chunks/labels is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_20//scene_chunks/labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_20//scene_chunks/videos/chunk_191.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_20//scene_chunks/videos/chunk_191.0_2.mp4\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_21//scene_chunks/videos is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_21//scene_chunks/videos\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_21//scene_chunks/labels is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_21//scene_chunks/labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([76, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_21//scene_chunks/videos/chunk_141.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([76, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_21//scene_chunks/videos/chunk_141.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([76, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_21//scene_chunks/videos/chunk_141.0_3.mp4\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_22//scene_chunks/videos is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_22//scene_chunks/videos\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_22//scene_chunks/labels is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_22//scene_chunks/labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_22//scene_chunks/videos/chunk_407.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_22//scene_chunks/videos/chunk_407.0_2.mp4\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_23//scene_chunks/videos is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_23//scene_chunks/videos\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_23//scene_chunks/labels is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_23//scene_chunks/labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_23//scene_chunks/videos/chunk_27.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_23//scene_chunks/videos/chunk_27.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_23//scene_chunks/videos/chunk_27.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_23//scene_chunks/videos/chunk_27.0_4.mp4\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_24//scene_chunks/videos is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_24//scene_chunks/videos\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_24//scene_chunks/labels is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_24//scene_chunks/labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_24//scene_chunks/videos/chunk_224.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_24//scene_chunks/videos/chunk_224.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_24//scene_chunks/videos/chunk_224.0_3.mp4\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_25//scene_chunks/videos is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_25//scene_chunks/videos\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_25//scene_chunks/labels is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_25//scene_chunks/labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_25//scene_chunks/videos/chunk_144.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_25//scene_chunks/videos/chunk_144.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_25//scene_chunks/videos/chunk_91.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_25//scene_chunks/videos/chunk_91.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_25//scene_chunks/videos/chunk_222.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_25//scene_chunks/videos/chunk_222.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_25//scene_chunks/videos/chunk_288.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_25//scene_chunks/videos/chunk_288.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_25//scene_chunks/videos/chunk_288.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_25//scene_chunks/videos/chunk_288.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1280, 720])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_25//scene_chunks/videos/chunk_288.0_3.mp4\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_26//scene_chunks/videos is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_26//scene_chunks/videos\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_26//scene_chunks/labels is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_26//scene_chunks/labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_26//scene_chunks/videos/chunk_53.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_26//scene_chunks/videos/chunk_53.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_26//scene_chunks/videos/chunk_243.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_26//scene_chunks/videos/chunk_243.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_26//scene_chunks/videos/chunk_243.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_26//scene_chunks/videos/chunk_243.0_4.mp4\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_27//scene_chunks/videos is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_27//scene_chunks/videos\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_27//scene_chunks/labels is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_27//scene_chunks/labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_27//scene_chunks/videos/chunk_67.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_27//scene_chunks/videos/chunk_67.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_27//scene_chunks/videos/chunk_67.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_27//scene_chunks/videos/chunk_67.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_27//scene_chunks/videos/chunk_67.0_3.mp4\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_28//scene_chunks/videos is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_28//scene_chunks/videos\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_28//scene_chunks/labels is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_28//scene_chunks/labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_28//scene_chunks/videos/chunk_264.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_28//scene_chunks/videos/chunk_264.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_28//scene_chunks/videos/chunk_264.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_28//scene_chunks/videos/chunk_187.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_28//scene_chunks/videos/chunk_187.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_28//scene_chunks/videos/chunk_187.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_28//scene_chunks/videos/chunk_202.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_28//scene_chunks/videos/chunk_202.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_28//scene_chunks/videos/chunk_202.0_3.mp4\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_29//scene_chunks/videos is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_29//scene_chunks/videos\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_29//scene_chunks/labels is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_29//scene_chunks/labels\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_3//scene_chunks/videos is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_3//scene_chunks/videos\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_3//scene_chunks/labels is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_3//scene_chunks/labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 720, 1280])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_3//scene_chunks/videos/chunk_188.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 720, 1280])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_3//scene_chunks/videos/chunk_188.0_2.mp4\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_4//scene_chunks/videos is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_4//scene_chunks/videos\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_4//scene_chunks/labels is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_4//scene_chunks/labels\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_5//scene_chunks/videos is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_5//scene_chunks/videos\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_5//scene_chunks/labels is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_5//scene_chunks/labels\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_6//scene_chunks/videos is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_6//scene_chunks/videos\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_6//scene_chunks/labels is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_6//scene_chunks/labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_6//scene_chunks/videos/chunk_567.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_6//scene_chunks/videos/chunk_567.0_2.mp4\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_7//scene_chunks/videos is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_7//scene_chunks/videos\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_7//scene_chunks/labels is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_7//scene_chunks/labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_7//scene_chunks/videos/chunk_250.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_7//scene_chunks/videos/chunk_250.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_7//scene_chunks/videos/chunk_250.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_7//scene_chunks/videos/chunk_18.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_7//scene_chunks/videos/chunk_18.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_7//scene_chunks/videos/chunk_18.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_7//scene_chunks/videos/chunk_18.0_4.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_7//scene_chunks/videos/chunk_250.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_7//scene_chunks/videos/chunk_250.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_7//scene_chunks/videos/chunk_250.0_3.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_7//scene_chunks/videos/chunk_250.0_4.mp4\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_8//scene_chunks/videos is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_8//scene_chunks/videos\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_8//scene_chunks/labels is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_8//scene_chunks/labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_8//scene_chunks/videos/chunk_161.0_1.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_8//scene_chunks/videos/chunk_161.0_2.mp4\n",
      "samples dtype:torch.float32\n",
      "samples shape:torch.Size([90, 3, 1920, 1080])\n",
      "/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_8//scene_chunks/videos/chunk_161.0_3.mp4\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_9//scene_chunks/videos is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_9//scene_chunks/videos\n",
      "warning: the folder/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_9//scene_chunks/labels is not exist\n",
      "create folder /mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test_9//scene_chunks/labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n",
      "/tmp/ipykernel_1788445/3037519057.py:5: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_path = '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站/'\n",
    "for root, dirs, files in os.walk(root_path):\n",
    "    # 如果你只想获取下一层的子目录，可以在这里筛选\n",
    "    if root == root_path:\n",
    "        # root_dir 下的直接子目录就是 dirs 中的项\n",
    "        for dir in dirs:\n",
    "            split_video_with_chunk(root_path,dir)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
