{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "80530004-32a2-4a53-89f3-2689aadbecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfbc555-b4ca-467d-af52-ee22a2f3fdb2",
   "metadata": {},
   "source": [
    "### 按照环境后需要重启虚拟机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "89d8c4cb-3b93-4afe-b8fe-5b72def93629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting Pillow==10.1.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e5/b9/5c6ad3241f1ccca4b781dfeddbab2dac4480f95aedc351a0e60c9f4c8aa9/Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch==2.1.2\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/03/f1/13137340776dd5d5bcfd2574c9c6dfcc7618285035cd77240496e5c1a79b/torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.16.2\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/da/ae/76bd3682465730dea7be21f36a8160a911a470de6f26228904f222e7fefe/torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting transformers==4.40.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/09/c8/844d5518a6aeb4ffdc0cf0cae65ae13dbe5838306728c5c640b5a6e2a0c9/transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece==0.1.99 in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (0.1.99)\n",
      "Collecting accelerate==0.30.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e9/bb/1edd2c836071e91d2bd331b9542bbd592e23d1474645b9c6fd56232caace/accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting bitsandbytes==0.43.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/2f/a4/d8c8c1f69ceb3afdc285d62c65bec8d46900d70e81c9a8b24883001e23f8/bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting peft==0.9.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/08/87/3e7eb34ac06d3f4ac72e2302e9e69bef12247a8a627c59a4d8a498135727/peft-0.9.0-py3-none-any.whl (190 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (from torch==2.1.2) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (from torch==2.1.2) (4.7.1)\n",
      "Requirement already satisfied: sympy in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (from torch==2.1.2) (1.12)\n",
      "Requirement already satisfied: networkx in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (from torch==2.1.2) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (from torch==2.1.2) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (from torch==2.1.2) (2023.9.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/b6/9f/c64c03f49d6fbc56196664d05dba14e3a561038a81a638eeb47f4d4cfd48/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/eb/d5/c68b1d2cdfcc59e72e8a5949a37ddb22ae6cade80cd4a57a84d4c8b55472/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/7e/00/6b218edd739ecfc60524e585ba8e6b00554dd908de2c9c66c1af3e44e18d/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ff/74/a2e2be7fb83aaedec84f391f082cf765dfb635e7caa9b49065f73e4835d8/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/37/6d/121efd7382d5b0284239f4ab1fc1590d86d34ed4a4a2fdb13b30ca8e5740/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/86/94/eb540db023ce1d162e7bea9f8f5aa781d57c65aed513c33ee9a5123ead4d/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/44/31/4890b1c9abc496303412947fc7dcea3d14861720642b49e8ceed89636705/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/bc/1d/8de1e5c67099015c834315e333911273a8c6aaba78923dd1d1e25fc5f217/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/65/5b/cfaeebf25cd9fdec14338ccb16f6b2c4c7fa9163aefcf057d86b9cc248bb/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a4/05/23f8f38eec3d28e4915725b233c24d8f1a33cb6540a882f7b54be1befa02/nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/da/d3/8057f0587683ed2fcd4dbfbdfdfa807b9160b809976099d36b8f60d08f03/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==2.1.0 (from torch==2.1.2)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4d/22/91a8af421c8a8902dde76e6ef3db01b258af16c53d81e8c0d0dc13900a9e/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (from torchvision==0.16.2) (1.24.4)\n",
      "Requirement already satisfied: requests in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (from torchvision==0.16.2) (2.31.0)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers==4.40.0)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/b9/8f/d6718641c14d98a5848c6a24d2376028d292074ffade0702940a4b1dde76/huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (from transformers==4.40.0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (from transformers==4.40.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (from transformers==4.40.0) (2023.8.8)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.40.0)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/40/4f/eb78de4af3b17b589f43a369cbf0c3a7173f25c3d2cd93068852c07689aa/tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.40.0)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/b9/df/6f766b56690709d22e83836e4067a1109a7d84ea152a6deb5692743a2805/safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (from transformers==4.40.0) (4.66.1)\n",
      "Requirement already satisfied: psutil in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (from accelerate==0.30.1) (5.9.5)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a8/48/a9775d377cb95585fb188b469387f58ba6738e268de22eae2ad4cedb2c41/nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (from jinja2->torch==2.1.2) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (from requests->torchvision==0.16.2) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (from requests->torchvision==0.16.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (from requests->torchvision==0.16.2) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (from requests->torchvision==0.16.2) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages (from sympy->torch==2.1.2) (1.3.0)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: safetensors, Pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, torchvision, bitsandbytes, accelerate, peft\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.3.3\n",
      "    Uninstalling safetensors-0.3.3:\n",
      "      Successfully uninstalled safetensors-0.3.3\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 10.0.0\n",
      "    Uninstalling Pillow-10.0.0:\n",
      "      Successfully uninstalled Pillow-10.0.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.0.0\n",
      "    Uninstalling triton-2.0.0:\n",
      "      Successfully uninstalled triton-2.0.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.16.4\n",
      "    Uninstalling huggingface-hub-0.16.4:\n",
      "      Successfully uninstalled huggingface-hub-0.16.4\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.33.1\n",
      "    Uninstalling transformers-4.33.1:\n",
      "      Successfully uninstalled transformers-4.33.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.1\n",
      "    Uninstalling torch-2.0.1:\n",
      "      Successfully uninstalled torch-2.0.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.15.2\n",
      "    Uninstalling torchvision-0.15.2:\n",
      "      Successfully uninstalled torchvision-0.15.2\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.22.0\n",
      "    Uninstalling accelerate-0.22.0:\n",
      "      Successfully uninstalled accelerate-0.22.0\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.5.0\n",
      "    Uninstalling peft-0.5.0:\n",
      "      Successfully uninstalled peft-0.5.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "openai-whisper 20230314 requires triton==2.0.0, but you have triton 2.1.0 which is incompatible.\n",
      "torchaudio 2.0.2 requires torch==2.0.1, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Pillow-10.1.0 accelerate-0.30.1 bitsandbytes-0.43.1 huggingface-hub-0.24.6 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 peft-0.9.0 safetensors-0.4.5 tokenizers-0.19.1 torch-2.1.2 torchvision-0.16.2 transformers-4.40.0 triton-2.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow==10.1.0 torch==2.1.2 torchvision==0.16.2 transformers==4.40.0 sentencepiece==0.1.99 accelerate==0.30.1 bitsandbytes==0.43.1 peft==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84464db1-832e-4f0e-a19a-f3178963a018",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/mnt/ceph/develop/jiawei/conda_env/keyframe_extra/lib/python3.10/site-packages/transformers/quantizers/auto.py:159: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.18s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor\n",
    "\n",
    "model_path = '/mnt/ceph/develop/jiawei/ComfyUI/models/LLM/MiniCPMv2_6-prompt-generator'\n",
    "attention = 'sdpa'\n",
    "precision = 'fp16'\n",
    "dtype = {\"bf16\": torch.bfloat16, \"fp16\": torch.float16, \"fp32\": torch.float32}[precision]\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, attn_implementation=attention,\n",
    "                                                         torch_dtype=dtype, load_in_4bit=True, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d5d2d46-5533-42b0-89c8-08a47ad4c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "\n",
    "\n",
    "def read_fps(video_path:str):\n",
    "    # 打开视频文件\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # 获取视频的帧速率\n",
    "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "     \n",
    "    # 释放视频捕获对象\n",
    "    video_capture.release()\n",
    "    \n",
    "    # 关闭视频文件\n",
    "    cv2.destroyAllWindows()\n",
    "    return fps\n",
    "\n",
    "\"\"\"\n",
    "根据fps转换帧\n",
    "\n",
    "为 %H:%M:%S,%f\n",
    "\"\"\"\n",
    "def frame_to_timecode(frame, fps):\n",
    "    # 计算总秒数\n",
    "    total_seconds = frame / fps\n",
    "\n",
    "    # 分离出小时、分钟、秒和毫秒\n",
    "    hours = math.floor(total_seconds // 3600)\n",
    "    minutes = math.floor((total_seconds % 3600) // 60)\n",
    "    seconds = math.floor(total_seconds % 60)\n",
    "    milliseconds = (total_seconds - math.floor(total_seconds)) * 1000\n",
    "\n",
    "    # 返回格式化时间\n",
    "    return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02},{int(milliseconds):03}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "243a52c8-4730-4864-9934-ec15a56a5ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "'''\n",
    "获取输入文件夹内的所有load_keyframe文件，并返回文件名列表\n",
    "'''\n",
    "def load_keyframe(file_dir):\n",
    "    L = []\n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        for file in files:\n",
    "            if os.path.splitext(file)[1] == '.jpg': \n",
    "                # 使用os.path.basename获取文件名（包括扩展名）\n",
    "                file_name_with_extension = os.path.basename(file)\n",
    "                # 使用os.path.splitext获取文件名和扩展名的分隔结果\n",
    "                file_name, file_extension = os.path.splitext(file_name_with_extension)\n",
    "                L.append(int(file_name))\n",
    "        L.sort()  # Sort the list of filenames\n",
    "        return L \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa4dd354-3023-41f7-94c8-42539a12254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "def get_scenes_timeline(scenes_path):\n",
    "    # Get lens segmentation data\n",
    "    number_list = []\n",
    "    with open(scenes_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "            numbers = line.strip().split(' ')\n",
    "            print(numbers)\n",
    "            number_list.extend([int(number) for number in numbers])\n",
    "\n",
    "    return number_list\n",
    "\n",
    "def find_neighbors(timeline, current_keyframe):\n",
    "    # 找到 current_keyframe 在时间线中的位置\n",
    "    if current_keyframe in timeline:\n",
    "        index = timeline.index(current_keyframe)\n",
    "        # 获取前后的两个数字\n",
    "        prev_keyframe = timeline[index - 1] if index - 1 >= 0 else None\n",
    "        next_keyframe = timeline[index + 1] if index + 1 < len(timeline) else None\n",
    "        return prev_keyframe, next_keyframe\n",
    "    else:\n",
    "        return None, None  # 如果找不到，返回None\n",
    "\n",
    "\n",
    "def scenes_timeline_pad(csv_path, fps, features_keyframes, scenes_timeline):\n",
    "\n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(csv_path) \n",
    "    # 检查分镜和特征帧是否连续，并补全缺失的行\n",
    "    for i in range(1, len(features_keyframes)): \n",
    "        current_keyframe = features_keyframes[i]\n",
    "        \n",
    "        # 如果特征帧不存在，插入新的行\n",
    "        if not current_keyframe in df['特征帧'].values:\n",
    "\n",
    "            # 找到前后的数字\n",
    "            prev_keyframe, next_keyframe = find_neighbors(scenes_timeline, current_keyframe)\n",
    "            \n",
    "            if prev_keyframe:\n",
    "                new_row = {\n",
    "                    '内容': '',  \n",
    "                    '开始时间': frame_to_timecode(prev_keyframe, fps), \n",
    "                    '结束时间': frame_to_timecode(next_keyframe, fps),\n",
    "                    '分镜': i,  # 填入当前的分镜编号\n",
    "                    '特征帧': current_keyframe\n",
    "                }\n",
    "            else:\n",
    "                new_row = {\n",
    "                    '内容': '',   \n",
    "                    '开始时间': '',  \n",
    "                    '结束时间': '',\n",
    "                    '分镜': i,  # 填入当前的分镜编号\n",
    "                    '特征帧': current_keyframe\n",
    "                }\n",
    "            df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "    df = df.sort_values(by='特征帧', ascending=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c721f6e1-6aac-4d1c-bf62-bdb23f2c0fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\"\"\"\n",
    "增加场景描述\n",
    "\"\"\"\n",
    "def scenes_timeline_caption(df, features_folder_path,caption_method, features_keyframes, scenes_timeline):\n",
    " \n",
    "\n",
    "    if caption_method == 'short_prompt':\n",
    "        prompt = \"Provide a detailed description of the details and content contained in the image, and generate a short prompt that can be used for image generation tasks in Stable Diffusion,you should only return prompt，itself without any additional information.\"\n",
    "    elif caption_method == 'long_prompt':\n",
    "        prompt = \"\"\"Follow these steps to create a Midjourney-style long prompt for generating high-quality images: \n",
    "            1. The prompt should include rich details, vivid scenes, and composition information, capturing the important elements that make up the scene. \n",
    "            2. You can appropriately add some details to enhance the vividness and richness of the content, while ensuring that the long prompt does not exceed 256 tokens,you should only return prompt，itself without any additional information\"\"\"\n",
    "    else:\n",
    "        prompt = \"Describe this image in detail, focusing on the main elements, colors, and overall composition. After the description, generate a list of relevant tags that could be used for image generation task with Stable Diffusion.\"\n",
    "\n",
    "    feature_description_map = {}\n",
    "    # 检查分镜和特征帧是否连续，并补全缺失的行\n",
    "    for i in range(1, len(features_keyframes)): \n",
    "        current_keyframe = features_keyframes[i]\n",
    "        \n",
    "        current_keyframe_image = os.path.join(features_folder_path, f\"{current_keyframe}.jpg\")\n",
    "        image = Image.open(current_keyframe_image).convert('RGB')\n",
    "        \n",
    "        # Prepare the input for the chat method\n",
    "        msgs = [{\"role\": \"user\", \"content\": [image, prompt]}]\n",
    "        # Use the chat method\n",
    "        generated_text = model.chat(\n",
    "            image=[image],\n",
    "            msgs=msgs,\n",
    "            tokenizer=tokenizer,\n",
    "            processor=processor,\n",
    "            max_new_tokens=2048,\n",
    "            sampling=False,\n",
    "            num_beams=3\n",
    "        )\n",
    "        feature_description_map[current_keyframe] = generated_text \n",
    "        \n",
    "    # 增加一列 \"特征描述\"，根据 \"特征帧\" 值从字典中获取描述\n",
    "    df['特征描述'] = df['特征帧'].map(feature_description_map)\n",
    "    \n",
    "    # 如果特征帧没有对应的描述，可以设置一个默认描述（可选）\n",
    "    df['特征描述'].fillna('默认描述', inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "504143d7-7fb1-400c-825d-66b798378d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_keyframe_add_scene_caption(root_path,video_source):\n",
    "    scenes_path=f'{root_path}/{video_source}/{video_source}.mp4.scenes.txt'\n",
    "    save_path = f'{root_path}/{video_source}/'\n",
    "    video_path=f'{save_path}/{video_source}.mp4'\n",
    "    csv_path=f'{save_path}/str/{video_source}_keyframe.csv'\n",
    "    output_scene_path=f'{save_path}/scene'\n",
    "    output_csv_path=f'{output_scene_path}/{video_source}_scene_keyframe.csv'\n",
    "\n",
    "    features_folder_path=f'{save_path}/{video_source}-features-result-cuda'\n",
    "    print(\"save_path{}\".format(save_path))\n",
    "    print(\"video_path{}\".format(video_path))\n",
    "    print(\"csv_path{}\".format(csv_path))\n",
    "    print(\"output_csv_path{}\".format(output_csv_path))\n",
    "    print(\"features_folder_path:{}\".format(features_folder_path))\n",
    "    \n",
    "    # checking if srt_folder is a folder\n",
    "    if not os.path.isdir(output_scene_path):\n",
    "        print('warning: the folder{} is not exist'.format(output_scene_path))\n",
    "        # create srt_folder\n",
    "        os.makedirs(output_scene_path)\n",
    "        print('create folder', output_scene_path) \n",
    "    features_keyframes=load_keyframe(features_folder_path) \n",
    "    print(\"获取features_keyframes，成功{}\".format(features_keyframes))\n",
    "    fps = read_fps(video_path)\n",
    "    scenes_timeline = get_scenes_timeline(scenes_path)\n",
    "    print(f\"senes_timeline:{scenes_timeline}\")\n",
    "\n",
    "    pd_data = scenes_timeline_pad(csv_path, fps, features_keyframes, scenes_timeline)\n",
    "    pd_data = scenes_timeline_caption(pd_data,features_folder_path, caption_method='long_prompt', features_keyframes=features_keyframes, scenes_timeline=scenes_timeline)\n",
    "    \n",
    "    pd_data.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a4f9c4-283d-4b44-8d33-c7d1a6e4f7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_path/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test1/\n",
      "video_path/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test1//test1.mp4\n",
      "csv_path/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test1//str/test1_keyframe.csv\n",
      "output_csv_path/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test1//scene/test1_scene_keyframe.csv\n",
      "features_folder_path:/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test1//test1-features-result-cuda\n",
      "获取features_keyframes，成功[122]\n",
      "0 315\n",
      "\n",
      "['0', '315']\n",
      "senes_timeline:[0, 315]\n",
      "save_path/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test2/\n",
      "video_path/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test2//test2.mp4\n",
      "csv_path/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test2//str/test2_keyframe.csv\n",
      "output_csv_path/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test2//scene/test2_scene_keyframe.csv\n",
      "features_folder_path:/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站//test2//test2-features-result-cuda\n",
      "获取features_keyframes，成功[45, 91, 113, 148, 177, 197, 212, 248, 307, 407, 496]\n",
      "0 81\n",
      "\n",
      "['0', '81']\n",
      "82 167\n",
      "\n",
      "['82', '167']\n",
      "168 196\n",
      "\n",
      "['168', '196']\n",
      "197 238\n",
      "\n",
      "['197', '238']\n",
      "239 293\n",
      "\n",
      "['239', '293']\n",
      "294 344\n",
      "\n",
      "['294', '344']\n",
      "345 487\n",
      "\n",
      "['345', '487']\n",
      "488 523\n",
      "\n",
      "['488', '523']\n",
      "senes_timeline:[0, 81, 82, 167, 168, 196, 197, 238, 239, 293, 294, 344, 345, 487, 488, 523]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_578289/2214287067.py:44: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '默认描述' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df['特征描述'].fillna('默认描述', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_path = '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/B站/'\n",
    "for root, dirs, files in os.walk(root_path):\n",
    "    # 如果你只想获取下一层的子目录，可以在这里筛选\n",
    "    if root == root_path:\n",
    "        # root_dir 下的直接子目录就是 dirs 中的项\n",
    "        for dir in dirs:\n",
    "            \n",
    "            csv_keyframe_add_scene_caption(root_path,dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000e616a-b682-4ab2-ae67-fce8a58b3c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c93293-a659-4aa9-a98a-d8f433028653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
