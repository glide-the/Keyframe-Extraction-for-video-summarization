{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "189aa187-8be8-4407-9b89-8a4bdfcee893",
   "metadata": {},
   "source": [
    "### 注意。不能同时执行，因为写入的是一个文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9446291-5dd7-408b-8a2d-a888c4bb7df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def check_output_folder(output_folder):\n",
    "    if not os.path.isdir(output_folder):\n",
    "        print('warning: the folder{} is not exist'.format(output_folder))\n",
    "        # create srt_folder\n",
    "        os.makedirs(output_folder)\n",
    "        print('create folder', output_folder)\n",
    "\n",
    "def load_file_by_extension(file_dir, extension):\n",
    "    L = []\n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        for file in files:\n",
    "            if os.path.splitext(file)[1] == f'.{extension}':  \n",
    "                L.append(file) \n",
    "        return L \n",
    "\n",
    "def video_dataset_sat_to_hf(root_path, video_source, output_dir):\n",
    "    save_path = f'{root_path}/{video_source}/' \n",
    "  \n",
    "    videos_output_dir = f'{save_path}/scene_chunks/videos'\n",
    "    labels_output_dir = f'{save_path}/scene_chunks/labels'\n",
    "    videos_files = load_file_by_extension(videos_output_dir, 'mp4')\n",
    "    labels_files = load_file_by_extension(labels_output_dir, 'txt')\n",
    "\n",
    "    print(f\"load videos_files: {len(videos_files)}\")\n",
    "\n",
    "    prompts_file = f'{output_dir}/captions.txt'\n",
    "    videos_file = f'{output_dir}/videos.txt'\n",
    "\n",
    "    instance_videos = []\n",
    "    instance_prompts = []\n",
    "    videos_dir = f'{output_dir}/videos'\n",
    "    check_output_folder(videos_dir)\n",
    "    for i, filename in enumerate(videos_files):\n",
    "        video_path = f'{videos_output_dir}/{filename}' \n",
    "        label_filename = os.path.splitext(filename)[0] + '.txt'\n",
    "        label_path = f'{labels_output_dir}/{label_filename}'\n",
    "\n",
    "        if os.path.exists(video_path) and os.path.exists(label_path):\n",
    "            # Copy video to output directory\n",
    "            output_video_path = f'{videos_dir}/{video_source}_{filename}' \n",
    "            shutil.copy(video_path, output_video_path)\n",
    "            instance_videos.append(f'videos/{video_source}_{filename}')\n",
    "\n",
    "            # Read and append prompt\n",
    "            with open(label_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                prompt_data = [line.strip() for line in file.readlines() if len(line.strip()) > 0]\n",
    "                instance_prompts.append(\"\".join(prompt_data))\n",
    "\n",
    "    # Write instance_videos to videos_file\n",
    "    with open(videos_file, \"a\", encoding=\"utf-8\") as vf:\n",
    "        for video in instance_videos:\n",
    "            vf.write(video + '\\n')\n",
    "\n",
    "    # Write instance_prompts to prompts_file\n",
    "    with open(prompts_file, \"a\", encoding=\"utf-8\") as pf:\n",
    "        for prompt in instance_prompts:\n",
    "            pf.write(prompt + '\\n')\n",
    "\n",
    "    print(f\"Copied {len(instance_videos)} videos and saved corresponding prompts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db1bacf7-4ab1-408a-98c0-39ed2cf03542",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# dir_put = '/mnt/ceph/develop/jiawei/lora_dataset/hf_cogvideo_tom_jerry_dataset'\n",
    " \n",
    "# video_dataset_sat_to_hf('/mnt/ceph/develop/jiawei/lora_dataset/speech_data/猫和老鼠/',\n",
    "#                         'test_1',dir_put )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc617e73-7cce-4e12-9e64-0eb0f67fa757",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load videos_files: 578\n",
      "Copied 289 videos and saved corresponding prompts.\n",
      "load videos_files: 17\n",
      "Copied 17 videos and saved corresponding prompts.\n",
      "load videos_files: 64\n",
      "Copied 64 videos and saved corresponding prompts.\n",
      "load videos_files: 30\n",
      "Copied 30 videos and saved corresponding prompts.\n",
      "load videos_files: 11\n",
      "Copied 11 videos and saved corresponding prompts.\n",
      "load videos_files: 297\n",
      "Copied 297 videos and saved corresponding prompts.\n",
      "load videos_files: 30\n",
      "Copied 30 videos and saved corresponding prompts.\n",
      "load videos_files: 12\n",
      "Copied 12 videos and saved corresponding prompts.\n",
      "load videos_files: 43\n",
      "Copied 43 videos and saved corresponding prompts.\n",
      "load videos_files: 50\n",
      "Copied 50 videos and saved corresponding prompts.\n",
      "load videos_files: 50\n",
      "Copied 50 videos and saved corresponding prompts.\n",
      "load videos_files: 297\n",
      "Copied 297 videos and saved corresponding prompts.\n",
      "load videos_files: 270\n",
      "Copied 270 videos and saved corresponding prompts.\n",
      "load videos_files: 291\n",
      "Copied 291 videos and saved corresponding prompts.\n",
      "load videos_files: 90\n",
      "Copied 90 videos and saved corresponding prompts.\n",
      "load videos_files: 19\n",
      "Copied 19 videos and saved corresponding prompts.\n",
      "load videos_files: 139\n",
      "Copied 139 videos and saved corresponding prompts.\n",
      "load videos_files: 61\n",
      "Copied 61 videos and saved corresponding prompts.\n",
      "load videos_files: 34\n",
      "Copied 34 videos and saved corresponding prompts.\n",
      "load videos_files: 43\n",
      "Copied 43 videos and saved corresponding prompts.\n",
      "load videos_files: 271\n",
      "Copied 271 videos and saved corresponding prompts.\n",
      "load videos_files: 130\n",
      "Copied 130 videos and saved corresponding prompts.\n",
      "load videos_files: 207\n",
      "Copied 207 videos and saved corresponding prompts.\n",
      "load videos_files: 49\n",
      "Copied 49 videos and saved corresponding prompts.\n",
      "load videos_files: 25\n",
      "Copied 25 videos and saved corresponding prompts.\n",
      "load videos_files: 327\n",
      "Copied 327 videos and saved corresponding prompts.\n",
      "load videos_files: 25\n",
      "Copied 25 videos and saved corresponding prompts.\n",
      "load videos_files: 3797\n",
      "Copied 3797 videos and saved corresponding prompts.\n",
      "load videos_files: 224\n",
      "Copied 224 videos and saved corresponding prompts.\n",
      "load videos_files: 4268\n",
      "Copied 4268 videos and saved corresponding prompts.\n",
      "load videos_files: 883\n",
      "Copied 883 videos and saved corresponding prompts.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "dir_put = '/mnt/ceph/develop/jiawei/lora_dataset/hf_cogvideo_tom_jerry_dataset'\n",
    "root_path = '/mnt/ceph/develop/jiawei/lora_dataset/speech_data/猫和老鼠6/'\n",
    "check_output_folder(dir_put)\n",
    "for root, dirs, files in os.walk(root_path):\n",
    "    # 如果你只想获取下一层的子目录，可以在这里筛选\n",
    "    if root == root_path:\n",
    "        # root_dir 下的直接子目录就是 dirs 中的项\n",
    "        for dir in dirs:\n",
    "            video_dataset_sat_to_hf(root_path,dir,dir_put)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9725fc72-0f7f-40c3-be52-bb3050fe9638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
